{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import load_pickle, dump_pickle, raw_data_path, feature_data_path\n",
    "\n",
    "from _2_2_gen_statistics_features import add_feature_click_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gap_before(s):\n",
    "    time_now,times = s.split('-')\n",
    "    times = times.split(':')\n",
    "    gaps = []\n",
    "    for t in times:\n",
    "        this_gap = int(time_now) - int(t)\n",
    "        if this_gap>0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "        \n",
    "def get_gap_after(s):\n",
    "    time_now,times = s.split('-')\n",
    "    times = times.split(':')\n",
    "    gaps = []\n",
    "    for t in times:\n",
    "        this_gap = int(t) - int(time_now)\n",
    "        if this_gap>0:\n",
    "            gaps.append(this_gap)\n",
    "    if len(gaps)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return min(gaps)\n",
    "    \n",
    "def get_true_rank(s):\n",
    "    time_now,times = s.split('-')\n",
    "    times = times.split(':')\n",
    "    gaps = []\n",
    "    for t in times:\n",
    "        this_gap = int(time_now) - int(t)\n",
    "        if this_gap < 0:\n",
    "            gaps.append(this_gap)\n",
    "    return len(gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用户当前点击在一天中的排序\n",
    "        0: 只有一次点击\n",
    "        1: 第一次点击\n",
    "        2: 非首尾点击\n",
    "        3: 最后一次点击"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_day_rank_mapper(row):\n",
    "    '''\n",
    "\n",
    "    return:\n",
    "        0: 只有一次点击\n",
    "        1: 第一次点击\n",
    "        2: 非首尾点击\n",
    "        3: 最后一次点击\n",
    "\n",
    "    '''\n",
    "    if row['user_click_day'] <= 1:\n",
    "        return 0\n",
    "    elif row['user_first_click_day'] > 0:\n",
    "        return 1\n",
    "    elif row['user_last_click_day'] > 0:\n",
    "        return 3\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "def gen_user_click_rank_day(update=True):\n",
    "    '''生成用户当前点击在一天中的排序\n",
    "\n",
    "    file_name: user_click_day_rank.pkl\n",
    "\n",
    "    features:\n",
    "        'user_click_rank_day', \n",
    "        'user_first_click_day', \n",
    "        'user_last_click_day'\n",
    "\n",
    "    '''\n",
    "\n",
    "    data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "\n",
    "    feature_path = feature_data_path + 'user_click_rank_day.pkl'\n",
    "\n",
    "    if os.path.exists(feature_path) and update == False:\n",
    "        print('found '+feature_path)\n",
    "    else:\n",
    "        print('generating '+feature_path)\n",
    "\n",
    "        user_click_day = data.groupby(['user_id', 'day']).size(\n",
    "        ).reset_index().rename(columns={0: 'user_click_day'})\n",
    "\n",
    "        data = pd.merge(data, user_click_day, how='left',\n",
    "                        on=['user_id', 'day'])\n",
    "\n",
    "        instance = data.groupby(['instance_id']).size(\n",
    "        ).reset_index().rename(columns={0: 'instance_num'})\n",
    "\n",
    "        # 用户在一天内点击该物品的时间戳排序\n",
    "        sorted_data = data.sort_values(\n",
    "            by=['user_id', 'day', 'context_timestamp'], ascending=True)\n",
    "\n",
    "        # 保留一天内用户首次点击该物品的记录\n",
    "        first = sorted_data.drop_duplicates(['user_id', 'day']).copy()\n",
    "\n",
    "        # 保留一天内用户最后一次点击该物品的记录\n",
    "        last = sorted_data.drop_duplicates(\n",
    "            ['user_id', 'day'], keep='last').copy()\n",
    "\n",
    "        first['user_first_click_day'] = 1\n",
    "        first = first[['user_first_click_day']]\n",
    "        data = data.join(first)\n",
    "\n",
    "        last['user_last_click_day'] = 1\n",
    "        last = last[['user_last_click_day']]\n",
    "        data = data.join(last)\n",
    "\n",
    "        data[['user_first_click_day', 'user_last_click_day']] = data[[\n",
    "            'user_first_click_day', 'user_last_click_day']].fillna(0)\n",
    "\n",
    "        data['user_click_rank_day'] = data.apply(user_day_rank_mapper, axis=1)\n",
    "\n",
    "        data = data[['user_click_rank_day',\n",
    "                     'user_first_click_day', 'user_last_click_day']]\n",
    "        dump_pickle(data, feature_path)\n",
    "\n",
    "\n",
    "def add_user_click_rank_day(data):\n",
    "    '''添加用户当前点击在一天中的排序\n",
    "\n",
    "    join_key: ['instance_id',]\n",
    "\n",
    "    '''\n",
    "\n",
    "    feature_path = feature_data_path + 'user_click_rank_day.pkl'\n",
    "\n",
    "    if not os.path.exists(feature_path):\n",
    "        gen_user_click_rank_day()\n",
    "    user_click_rank_day = load_pickle(feature_path)\n",
    "    data = data.join(user_click_rank_day)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 添加用户当天点击的排名：user_click_true_rank_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_user_click_time_interval_day(update=True):\n",
    "    '''生成用户当前点击与当天首尾点击的时间间隔\n",
    "    \n",
    "    file_name: user_click_time_interval_day.pkl\n",
    "\n",
    "    features:\n",
    "        'user_click_interval_first_day', \n",
    "        'user_click_interval_last_day', \n",
    "        'user_click_true_rank_day', \n",
    "\n",
    "    '''\n",
    "\n",
    "    data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "\n",
    "    feature_path = feature_data_path + 'user_click_time_interval_day.pkl'\n",
    "\n",
    "    if os.path.exists(feature_path) and update == False:\n",
    "        print('found '+feature_path)\n",
    "    else:\n",
    "        print('generating '+feature_path)\n",
    "\n",
    "\n",
    "        # 用户在一天内点击该物品的时间戳排序\n",
    "        sorted_data = data.sort_values(\n",
    "            by=['user_id', 'day', 'context_timestamp'], ascending=True)\n",
    "\n",
    "        # 保留一天内用户首次点击该物品的记录\n",
    "        user_first_click_time_day = sorted_data.groupby(['user_id', 'day'])['context_timestamp'].first().reset_index().rename(columns={'context_timestamp': 'user_first_click_time_day'})\n",
    "        \n",
    "        # 保留一天内用户最后一次点击该物品的记录\n",
    "        user_last_click_time_day = sorted_data.groupby(['user_id', 'day'])['context_timestamp'].last().reset_index().rename(columns={'context_timestamp': 'user_last_click_time_day'})\n",
    "        \n",
    "        #保留一天内用户点击该物品的平均时间\n",
    "        user_mean_click_time_day = sorted_data.groupby(['user_id', 'day'])['context_timestamp'].mean().reset_index().rename(columns={'context_timestamp': 'user_mean_click_time_day'})\n",
    "\n",
    "        #计算一天内用户点击该物品时间的标准差\n",
    "        user_std_click_time_day = sorted_data.groupby(['user_id', 'day'])['context_timestamp'].std().reset_index().rename(columns={'context_timestamp': 'user_std_click_time_day'})\n",
    "        \n",
    "        data = pd.merge(data, user_first_click_time_day, 'left', on=['user_id', 'day'])\n",
    "        data = pd.merge(data, user_last_click_time_day, 'left', on=['user_id', 'day'])\n",
    "        data = pd.merge(data, user_mean_click_time_day, 'left', on=['user_id', 'day'])\n",
    "        data = pd.merge(data, user_std_click_time_day, 'left', on=['user_id', 'day'])\n",
    "        \n",
    "        data['user_click_interval_first_day'] = data['context_timestamp'] - data['user_first_click_time_day']\n",
    "        data['user_click_interval_last_day'] = data['user_last_click_time_day'] - data['context_timestamp']\n",
    "        data['user_click_interval_mean_day'] = data['context_timestamp'] - data['user_mean_click_time_day']\n",
    "        data['user_click_interval_diff_day'] = data['user_last_click_time_day'] - data['user_first_click_time_day']\n",
    "        data['user_click_interval_prob'] = data['user_click_interval_first_day'] / data['user_click_interval_diff_day']\n",
    "        \n",
    "        #计算当前点击时间与前一次后一次的时间差gap\n",
    "        t1 = data[['user_id', 'day', 'context_timestamp']]\n",
    "        t1.context_timestamp = t1.context_timestamp.astype('str')\n",
    "        t1 = t1.groupby(['user_id', 'day'])['context_timestamp'].agg(lambda x:':'.join(x)).reset_index()\n",
    "        t1.rename(columns={'context_timestamp':'times'},inplace=True)\n",
    "\n",
    "        t2 = data[['user_id', 'day', 'context_timestamp']]\n",
    "        t2 = pd.merge(t2, t1, on=['user_id', 'day'], how='left')\n",
    "        t2['time_now'] = t2.context_timestamp.astype('str') + '-' + t2.times\n",
    "        t2['time_gap_before'] = t2.time_now.apply(get_gap_before)\n",
    "        t2['time_gap_after'] = t2.time_now.apply(get_gap_after)\n",
    "        t2['user_click_true_rank_day'] = t2.time_now.apply(get_true_rank)\n",
    "        t3 = t2[['time_gap_before','time_gap_after', 'user_click_true_rank_day']]\n",
    "        \n",
    "        \n",
    "        data = data.join(t3)\n",
    "        \n",
    "        data = data[['user_click_interval_first_day', 'user_click_interval_last_day', \n",
    "                    'user_click_interval_diff_day','user_click_interval_prob',\n",
    "                     'time_gap_before','time_gap_after', 'user_click_true_rank_day']]\n",
    "        \n",
    "        dump_pickle(data, feature_path)\n",
    "\n",
    "\n",
    "def add_user_click_time_interval_day(data):\n",
    "    '''添加用户当前点击与当天首尾点击的时间间隔\n",
    "    \n",
    "    join_key: ['instance_id',]\n",
    "\n",
    "    '''\n",
    "\n",
    "    feature_path = feature_data_path + 'user_click_time_interval_day.pkl'\n",
    "\n",
    "    if not os.path.exists(feature_path):\n",
    "        gen_user_click_time_interval_day()\n",
    "        \n",
    "    user_click_interval_day = load_pickle(feature_path)\n",
    "    data = data.join(user_click_interval_day)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户全局点击的时间差特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_user_click_time_interval(update=True):\n",
    "    '''生成用户当前点击与当天首尾点击的时间间隔\n",
    "    \n",
    "    file_name: user_click_time_interval.pkl\n",
    "\n",
    "    features:\n",
    "\n",
    "    '''\n",
    "\n",
    "    data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "\n",
    "    feature_path = feature_data_path + 'user_click_time_interval.pkl'\n",
    "    \n",
    "\n",
    "    if os.path.exists(feature_path) and update == False:\n",
    "        print('found '+feature_path)\n",
    "    else:\n",
    "        print('generating '+feature_path)\n",
    "\n",
    "\n",
    "        # 用户点击该物品的时间戳排序，全局\n",
    "#         sorted_data = data.sort_values(\n",
    "#             by=['user_id', 'context_timestamp'], ascending=True)\n",
    "        \n",
    "        #保留一天内用户点击该物品的平均时间\n",
    "        user_mean_click_hour = data.groupby(['user_id',])['hour'].mean().reset_index().rename(columns={'hour': 'user_mean_click_hour'})\n",
    "        data = pd.merge(data, user_mean_click_hour, 'left', on=['user_id',])\n",
    "        data['user_click_interval_mean_hour'] = data['hour'] - data['user_mean_click_hour']\n",
    "        \n",
    "        #计算当前点击时间与前一次后一次的时间差gap\n",
    "        t1 = data[['user_id', 'context_timestamp']]\n",
    "        t1.context_timestamp = t1.context_timestamp.astype('str')\n",
    "        t1 = t1.groupby(['user_id', ])['context_timestamp'].agg(lambda x:':'.join(x)).reset_index()\n",
    "        t1.rename(columns={'context_timestamp':'times'},inplace=True)\n",
    "\n",
    "        t2 = data[['user_id', 'context_timestamp']]\n",
    "        t2 = pd.merge(t2, t1, on=['user_id', ], how='left')\n",
    "        t2['time_now'] = t2.context_timestamp.astype('str') + '-' + t2.times\n",
    "        t2['time_gap_before_total'] = t2.time_now.apply(get_gap_before)\n",
    "        t2['time_gap_after_total'] = t2.time_now.apply(get_gap_after)\n",
    "#         t2['user_click_true_rank_day'] = t2.time_now.apply(get_true_rank)\n",
    "        t3 = t2[['time_gap_before_total','time_gap_after_total',]]\n",
    "        \n",
    "        \n",
    "        data = data.join(t3)\n",
    "        \n",
    "        data = data[['user_click_interval_mean_hour', 'time_gap_before_total','time_gap_after_total',]]\n",
    "        \n",
    "        dump_pickle(data, feature_path)\n",
    "\n",
    "\n",
    "def add_user_click_time_interval(data):\n",
    "    '''添加用户当前点击与当天首尾点击的时间间隔\n",
    "    \n",
    "    join_key: ['instance_id',]\n",
    "\n",
    "    '''\n",
    "\n",
    "    feature_path = feature_data_path + 'user_click_time_interval.pkl'\n",
    "\n",
    "    if not os.path.exists(feature_path):\n",
    "        gen_user_click_time_interval()\n",
    "        \n",
    "    user_click_interval = load_pickle(feature_path)\n",
    "    data = data.join(user_click_interval)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全局：用户是第几次点击这个属性: 'user_' + feature + '_click_true_rank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_feature_rank_mapper(row):\n",
    "    '''\n",
    "\n",
    "    return:\n",
    "        0: 只有一次点击\n",
    "        1: 第一次点击\n",
    "        2: 非首尾点击\n",
    "        3: 最后一次点击\n",
    "\n",
    "    '''\n",
    "    if row['user_feature_click'] <= 1:\n",
    "        return 0\n",
    "    elif row['user_feature_first_click'] > 0:\n",
    "        return 1\n",
    "    elif row['user_feature_last_click'] > 0:\n",
    "        return 3\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "def gen_user_feature_click_rank(update=True):\n",
    "    '''用户是第几次点击这个属性\n",
    "\n",
    "    file_name: user_feature_click_rank.pkl\n",
    "\n",
    "    features:\n",
    "        'user_item_id_first_click', 'user_item_id_last_click',\n",
    "        'user_item_id_click_rank', 'user_item_id_first_click_interval',\n",
    "        'user_item_id_last_click_interval', 'user_item_brand_id_first_click',\n",
    "        'user_item_brand_id_last_click', 'user_item_brand_id_click_rank',\n",
    "        'user_item_brand_id_first_click_interval',\n",
    "        'user_item_brand_id_last_click_interval',\n",
    "        'user_item_city_id_first_click', 'user_item_city_id_last_click',\n",
    "        'user_item_city_id_click_rank',\n",
    "        'user_item_city_id_first_click_interval',\n",
    "        'user_item_city_id_last_click_interval', 'user_shop_id_first_click',\n",
    "        'user_shop_id_last_click', 'user_shop_id_click_rank',\n",
    "        'user_shop_id_first_click_interval',\n",
    "        'user_shop_id_last_click_interval'\n",
    "\n",
    "    '''\n",
    "\n",
    "    all_data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "\n",
    "    feature_path = feature_data_path + 'user_feature_click_rank.pkl'\n",
    "\n",
    "    feature_list = ['item_id', 'item_brand_id', 'shop_id', 'context_page_id', 'category2_label',]\n",
    "\n",
    "    for feature in tqdm(feature_list):\n",
    "\n",
    "        feature_path = feature_data_path + 'user_'+feature+'_click_rank.pkl'\n",
    "\n",
    "        if os.path.exists(feature_path) and update == False:\n",
    "            print('found '+feature_path)\n",
    "        else:\n",
    "            print('generating '+feature_path)\n",
    "\n",
    "            first_click_feature_name = 'user_' + feature + '_first_click'\n",
    "            last_click_feature_name = 'user_' + feature + '_last_click'\n",
    "            rank_feature_name = 'user_' + feature + '_click_rank'\n",
    "            \n",
    "            true_rank_feature_name = 'user_' + feature + '_click_true_rank'\n",
    "            \n",
    "            first_click_time_name = 'user_' + feature + '_first_click_time'\n",
    "            last_click_time_name = 'user_' + feature + '_last_click_time'\n",
    "            first_click_interval_name = 'user_' + feature + '_first_click_interval'\n",
    "            last_click_interval_name = 'user_' + feature + '_last_click_interval'\n",
    "            \n",
    "            mean_click_time_name = 'user_' + feature + '_mean_click_time'\n",
    "            std_click_time_name = 'user_' + feature + '_std_click_time'\n",
    "            mean_click_interval_name = 'user_' + feature + '_mean_click_interval'\n",
    "            diff_click_interval_name = 'user_' + feature + '_diff_click_interval'\n",
    "            prob_click_interval_name = 'user_' + feature + '_prob_click_interval'\n",
    "            \n",
    "            time_gap_before_name = feature + '_time_gap_before'\n",
    "            time_gap_after_name = feature + '_time_gap_after'\n",
    "            \n",
    "            \n",
    "            user_feature_click = all_data.groupby(['user_id', feature]).size(\n",
    "            ).reset_index().rename(columns={0: 'user_feature_click'})\n",
    "\n",
    "            data = pd.merge(all_data, user_feature_click,\n",
    "                            how='left', on=['user_id', feature])\n",
    "\n",
    "            # 用户在一天内点击该物品的时间戳排序\n",
    "            sorted_data = data.sort_values(\n",
    "                by=['user_id', feature, 'context_timestamp'], ascending=True)[['user_id', feature, 'context_timestamp']]\n",
    "\n",
    "            #保留一天内用户点击该物品的平均时间\n",
    "            user_mean_click_time_feature = sorted_data.groupby(['user_id', feature])['context_timestamp'].mean().reset_index().rename(columns={'context_timestamp': mean_click_time_name})\n",
    "            #计算一天内用户点击该物品时间的标准差\n",
    "            user_std_click_time_feature = sorted_data.groupby(['user_id', feature])['context_timestamp'].std().reset_index().rename(columns={'context_timestamp': std_click_time_name})\n",
    "            \n",
    "            # 保留一天内用户首次点击该物品的记录\n",
    "            first = sorted_data.drop_duplicates(['user_id', feature]).copy()\n",
    "\n",
    "            # 保留一天内用户最后一次点击该物品的记录\n",
    "            last = sorted_data.drop_duplicates(\n",
    "                ['user_id', feature], keep='last').copy()\n",
    "\n",
    "            first.rename(columns = {'context_timestamp': first_click_time_name}, inplace=True)\n",
    "            last.rename(columns = {'context_timestamp': last_click_time_name}, inplace=True)\n",
    "\n",
    "            data = pd.merge(data, first, 'left', on=['user_id', feature])\n",
    "            data = pd.merge(data, last, 'left', on=['user_id', feature])\n",
    "            data = pd.merge(data, user_mean_click_time_feature, 'left', on=['user_id', feature])\n",
    "            data = pd.merge(data, user_std_click_time_feature, 'left', on=['user_id', feature])\n",
    "            \n",
    "\n",
    "            data[first_click_interval_name] = data['context_timestamp'] -  data[first_click_time_name]\n",
    "            data[last_click_interval_name] = data[last_click_time_name] -  data['context_timestamp']\n",
    "            data[mean_click_interval_name] = data['context_timestamp'] -  data[mean_click_time_name]\n",
    "            data[diff_click_interval_name] = data[last_click_time_name] -  data[first_click_time_name]\n",
    "            data[prob_click_interval_name] = data[first_click_interval_name] / data[diff_click_interval_name]\n",
    "            \n",
    "            first['user_feature_first_click'] = 1\n",
    "            first = first[['user_feature_first_click']]\n",
    "            data = data.join(first)\n",
    "\n",
    "            last['user_feature_last_click'] = 1\n",
    "            last = last[['user_feature_last_click']]\n",
    "            data = data.join(last)\n",
    "\n",
    "            data[['user_feature_first_click', 'user_feature_last_click']] = data[[\n",
    "                'user_feature_first_click', 'user_feature_last_click']].fillna(0)\n",
    "\n",
    "            data['user_feature_click_rank'] = data.apply(user_feature_rank_mapper, axis=1)\n",
    "\n",
    "            data.rename(columns={'user_feature_first_click': first_click_feature_name, 'user_feature_last_click': last_click_feature_name,\n",
    "                                 'user_feature_click_rank': rank_feature_name}, inplace=True)\n",
    "            \n",
    "            \n",
    "            #计算当前点击时间与前一次后一次的时间差gap\n",
    "            t1 = all_data[['user_id', feature, 'context_timestamp']]\n",
    "            t1.context_timestamp = t1.context_timestamp.astype('str')\n",
    "            t1 = t1.groupby(['user_id', feature])['context_timestamp'].agg(lambda x:':'.join(x)).reset_index()\n",
    "            t1.rename(columns={'context_timestamp':'times'},inplace=True)\n",
    "\n",
    "            t2 = all_data[['user_id', feature, 'context_timestamp']]\n",
    "            t2 = pd.merge(t2, t1, on=['user_id', feature], how='left')\n",
    "            t2['time_now'] = t2.context_timestamp.astype('str') + '-' + t2.times\n",
    "            t2[time_gap_before_name] = t2.time_now.apply(get_gap_before)\n",
    "            t2[time_gap_after_name] = t2.time_now.apply(get_gap_after)\n",
    "            t2[true_rank_feature_name] = t2.time_now.apply(get_true_rank)\n",
    "            t3 = t2[[time_gap_before_name,time_gap_after_name, true_rank_feature_name]]\n",
    "        \n",
    "            data = data.join(t3)\n",
    "            \n",
    "            data = data[[first_click_feature_name, last_click_feature_name,\n",
    "                         rank_feature_name, first_click_interval_name, last_click_interval_name,\n",
    "                        diff_click_interval_name, prob_click_interval_name,\n",
    "                        time_gap_before_name,time_gap_after_name,\n",
    "                        true_rank_feature_name]]\n",
    "            dump_pickle(data, feature_path)\n",
    "\n",
    "\n",
    "def add_user_feature_click_rank(data):\n",
    "    '''添加用户当前点击在一天中的排序\n",
    "\n",
    "    join_key: ['instance_id',]\n",
    "\n",
    "    '''\n",
    "\n",
    "    feature_list = ['item_id', 'item_brand_id', 'shop_id', 'context_page_id', 'category2_label',]\n",
    "\n",
    "    for feature in tqdm(feature_list):\n",
    "        feature_path = feature_data_path + 'user_'+feature+'_click_rank.pkl'\n",
    "        if not os.path.exists(feature_path):\n",
    "            gen_user_feature_click_rank()\n",
    "        user_feature_click_rank = load_pickle(feature_path)\n",
    "        data = data.join(user_feature_click_rank)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 当天：用户是第几次点击这个属性: 'user_' + feature + '_click_true_rank_day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_feature_rank_day_mapper(row):\n",
    "    '''\n",
    "\n",
    "    return:\n",
    "        0: 只有一次点击\n",
    "        1: 第一次点击\n",
    "        2: 非首尾点击\n",
    "        3: 最后一次点击\n",
    "\n",
    "    '''\n",
    "    if row['user_feature_click_day'] <= 1:\n",
    "        return 0\n",
    "    elif row['user_feature_first_click_day'] > 0:\n",
    "        return 1\n",
    "    elif row['user_feature_last_click_day'] > 0:\n",
    "        return 3\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "def gen_user_feature_click_rank_day(update=True):\n",
    "    '''用户是第几次点击这个属性\n",
    "\n",
    "    file_name: user_feature_click_rank_day.pkl\n",
    "\n",
    "    features:\n",
    "        'user_item_id_first_click', 'user_item_id_last_click',\n",
    "        'user_item_id_click_rank', 'user_item_id_first_click_interval',\n",
    "        'user_item_id_last_click_interval', 'user_item_brand_id_first_click',\n",
    "        'user_item_brand_id_last_click', 'user_item_brand_id_click_rank',\n",
    "        'user_item_brand_id_first_click_interval',\n",
    "        'user_item_brand_id_last_click_interval',\n",
    "        'user_item_city_id_first_click', 'user_item_city_id_last_click',\n",
    "        'user_item_city_id_click_rank',\n",
    "        'user_item_city_id_first_click_interval',\n",
    "        'user_item_city_id_last_click_interval', 'user_shop_id_first_click',\n",
    "        'user_shop_id_last_click', 'user_shop_id_click_rank',\n",
    "        'user_shop_id_first_click_interval',\n",
    "        'user_shop_id_last_click_interval'\n",
    "\n",
    "    '''\n",
    "\n",
    "    all_data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "\n",
    "#     feature_path = feature_data_path + 'user_feature_click_rank_day.pkl'\n",
    "\n",
    "    feature_list = ['item_id', 'item_brand_id',\n",
    "                    'shop_id', 'context_page_id', 'category2_label', ]\n",
    "\n",
    "    for feature in tqdm(feature_list):\n",
    "\n",
    "        feature_path = feature_data_path + 'user_'+feature + '_click_rank_day.pkl'\n",
    "\n",
    "        if os.path.exists(feature_path) and update == False:\n",
    "            print('found '+feature_path)\n",
    "        else:\n",
    "            print('generating '+feature_path)\n",
    "\n",
    "            first_click_feature_name = 'user_' + feature + '_first_click_day'\n",
    "            last_click_feature_name = 'user_' + feature + '_last_click_day'\n",
    "            rank_feature_name = 'user_' + feature + '_click_rank_day'\n",
    "\n",
    "            true_rank_feature_name = 'user_' + feature + '_click_true_rank_day'\n",
    "\n",
    "            first_click_time_name = 'user_' + feature + '_first_click_time_day'\n",
    "            last_click_time_name = 'user_' + feature + '_last_click_time_day'\n",
    "            first_click_interval_name = 'user_' + feature + '_first_click_interval_day'\n",
    "            last_click_interval_name = 'user_' + feature + '_last_click_interval_day'\n",
    "\n",
    "            mean_click_time_name = 'user_' + feature + '_mean_click_time_day'\n",
    "            std_click_time_name = 'user_' + feature + '_std_click_time_day'\n",
    "            mean_click_interval_name = 'user_' + feature + '_mean_click_interval_day'\n",
    "            diff_click_interval_name = 'user_' + feature + '_diff_click_interval_day'\n",
    "            prob_click_interval_name = 'user_' + feature + '_prob_click_interval_day'\n",
    "\n",
    "            time_gap_before_name = feature + '_time_gap_before_day'\n",
    "            time_gap_after_name = feature + '_time_gap_after_day'\n",
    "\n",
    "            user_feature_click_day = all_data.groupby(['user_id', feature, 'day']).size(\n",
    "            ).reset_index().rename(columns={0: 'user_feature_click_day'})\n",
    "\n",
    "            data = pd.merge(all_data, user_feature_click_day,\n",
    "                            how='left', on=['user_id', feature, 'day'])\n",
    "\n",
    "            # 用户在一天内点击该物品的时间戳排序\n",
    "            sorted_data = data.sort_values(\n",
    "                by=['user_id', feature, 'day', 'context_timestamp'], ascending=True)[['user_id', feature, 'day', 'context_timestamp']]\n",
    "\n",
    "            # 保留一天内用户点击该物品的平均时间\n",
    "            user_mean_click_time_feature = sorted_data.groupby(['user_id', feature, 'day'])['context_timestamp'].mean(\n",
    "            ).reset_index().rename(columns={'context_timestamp': mean_click_time_name})\n",
    "            # 计算一天内用户点击该物品时间的标准差\n",
    "            user_std_click_time_feature = sorted_data.groupby(['user_id', feature, 'day'])['context_timestamp'].std(\n",
    "            ).reset_index().rename(columns={'context_timestamp': std_click_time_name})\n",
    "\n",
    "            # 保留一天内用户首次点击该物品的记录\n",
    "            first = sorted_data.drop_duplicates(['user_id', feature, 'day']).copy()\n",
    "\n",
    "            # 保留一天内用户最后一次点击该物品的记录\n",
    "            last = sorted_data.drop_duplicates(\n",
    "                ['user_id', feature, 'day'], keep='last').copy()\n",
    "\n",
    "            first.rename(\n",
    "                columns={'context_timestamp': first_click_time_name}, inplace=True)\n",
    "            last.rename(\n",
    "                columns={'context_timestamp': last_click_time_name}, inplace=True)\n",
    "\n",
    "            data = pd.merge(data, first, 'left', on=['user_id', feature, 'day'])\n",
    "            data = pd.merge(data, last, 'left', on=['user_id', feature, 'day'])\n",
    "            data = pd.merge(data, user_mean_click_time_feature,\n",
    "                            'left', on=['user_id', feature, 'day'])\n",
    "            data = pd.merge(data, user_std_click_time_feature,\n",
    "                            'left', on=['user_id', feature, 'day'])\n",
    "\n",
    "            data[first_click_interval_name] = data['context_timestamp'] - \\\n",
    "                data[first_click_time_name]\n",
    "            data[last_click_interval_name] = data[last_click_time_name] - \\\n",
    "                data['context_timestamp']\n",
    "            data[mean_click_interval_name] = data['context_timestamp'] - \\\n",
    "                data[mean_click_time_name]\n",
    "            data[diff_click_interval_name] = data[last_click_time_name] - \\\n",
    "                data[first_click_time_name]\n",
    "            data[prob_click_interval_name] = data[first_click_interval_name] / \\\n",
    "                data[diff_click_interval_name]\n",
    "\n",
    "            first['user_feature_first_click_day'] = 1\n",
    "            first = first[['user_feature_first_click_day']]\n",
    "            data = data.join(first)\n",
    "\n",
    "            last['user_feature_last_click_day'] = 1\n",
    "            last = last[['user_feature_last_click_day']]\n",
    "            data = data.join(last)\n",
    "\n",
    "            data[['user_feature_first_click_day', 'user_feature_last_click_day']] = data[[\n",
    "                'user_feature_first_click_day', 'user_feature_last_click_day']].fillna(0)\n",
    "\n",
    "            data['user_feature_click_rank_day'] = data.apply(\n",
    "                user_feature_rank_day_mapper, axis=1)\n",
    "\n",
    "            data.rename(columns={'user_feature_first_click_day': first_click_feature_name, 'user_feature_last_click_day': last_click_feature_name,\n",
    "                                 'user_feature_click_rank_day': rank_feature_name}, inplace=True)\n",
    "\n",
    "            # 计算当前点击时间与前一次后一次的时间差gap\n",
    "            t1 = all_data[['user_id', 'day', feature, 'context_timestamp']]\n",
    "            t1.context_timestamp = t1.context_timestamp.astype('str')\n",
    "            t1 = t1.groupby(['user_id', feature, 'day'])['context_timestamp'].agg(\n",
    "                lambda x: ':'.join(x)).reset_index()\n",
    "            t1.rename(columns={'context_timestamp': 'times'}, inplace=True)\n",
    "\n",
    "            t2 = all_data[['user_id', 'day', feature, 'context_timestamp']]\n",
    "            t2 = pd.merge(t2, t1, on=['user_id', feature, 'day'], how='left')\n",
    "            t2['time_now'] = t2.context_timestamp.astype(\n",
    "                'str') + '-' + t2.times\n",
    "            t2[time_gap_before_name] = t2.time_now.apply(get_gap_before)\n",
    "            t2[time_gap_after_name] = t2.time_now.apply(get_gap_after)\n",
    "            t2[true_rank_feature_name] = t2.time_now.apply(get_true_rank)\n",
    "            t3 = t2[[time_gap_before_name,\n",
    "                     time_gap_after_name, true_rank_feature_name]]\n",
    "\n",
    "            data = data.join(t3)\n",
    "\n",
    "            data = data[[first_click_feature_name, last_click_feature_name,\n",
    "                         rank_feature_name, first_click_interval_name, last_click_interval_name,\n",
    "                         diff_click_interval_name, prob_click_interval_name,\n",
    "                         time_gap_before_name, time_gap_after_name,\n",
    "                         true_rank_feature_name]]\n",
    "            \n",
    "            dump_pickle(data, feature_path)\n",
    "\n",
    "\n",
    "def add_user_feature_click_rank_day(data):\n",
    "    '''添加用户当前点击在一天中的排序\n",
    "\n",
    "    join_key: ['instance_id',]\n",
    "\n",
    "    '''\n",
    "\n",
    "    feature_list = ['item_id', 'item_brand_id',\n",
    "                    'shop_id', 'context_page_id', 'category2_label', ]\n",
    "\n",
    "    for feature in tqdm(feature_list):\n",
    "        feature_path = feature_data_path + 'user_'+feature+'_click_rank_day.pkl'\n",
    "        if not os.path.exists(feature_path):\n",
    "            gen_user_feature_click_rank_day()\n",
    "        user_feature_click_rank_day = load_pickle(feature_path)\n",
    "        data = data.join(user_feature_click_rank_day)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# user click interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_click_rank_day.pkl\n",
      "generating ../features/user_click_time_interval_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_click_time_interval.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_item_id_click_rank.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|████████████████▊                                                                   | 1/5 [00:20<01:22, 20.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_item_brand_id_click_rank.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:41<01:01, 20.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_shop_id_click_rank.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [01:01<00:41, 20.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_context_page_id_click_rank.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [01:22<00:20, 20.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_category2_label_click_rank.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:45<00:00, 21.02s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:46<00:00, 21.34s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_item_id_click_rank_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|████████████████▊                                                                   | 1/5 [00:21<01:25, 21.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_item_brand_id_click_rank_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:42<01:03, 21.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_shop_id_click_rank_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [01:04<00:42, 21.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_context_page_id_click_rank_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [01:25<00:21, 21.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_category2_label_click_rank_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:47<00:00, 21.50s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:49<00:00, 21.90s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ =='__main__':\n",
    "    all_data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "    \n",
    "    all_data = add_user_click_rank_day(all_data)\n",
    "    all_data = add_user_click_time_interval_day(all_data)\n",
    "    all_data = add_user_click_time_interval(all_data)\n",
    "    \n",
    "    all_data = add_user_feature_click_rank(all_data)\n",
    "    all_data = add_user_feature_click_rank_day(all_data)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instance_id', 'item_id', 'item_category_list', 'item_property_list',\n",
       "       'item_brand_id', 'item_city_id', 'item_price_level', 'item_sales_level',\n",
       "       'item_collected_level', 'item_pv_level',\n",
       "       ...\n",
       "       'user_category2_label_first_click_day',\n",
       "       'user_category2_label_last_click_day',\n",
       "       'user_category2_label_click_rank_day',\n",
       "       'user_category2_label_first_click_interval_day',\n",
       "       'user_category2_label_last_click_interval_day',\n",
       "       'user_category2_label_diff_click_interval_day',\n",
       "       'user_category2_label_prob_click_interval_day',\n",
       "       'category2_label_time_gap_before_day',\n",
       "       'category2_label_time_gap_after_day',\n",
       "       'user_category2_label_click_true_rank_day'],\n",
       "      dtype='object', length=152)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_gap_before_total</th>\n",
       "      <th>time_gap_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>763</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2550</td>\n",
       "      <td>2550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6624</td>\n",
       "      <td>6624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3124</td>\n",
       "      <td>3124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3196</td>\n",
       "      <td>3196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>138</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539340</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539341</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539342</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539343</th>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539344</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539345</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539346</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539347</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539348</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539349</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539350</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539351</th>\n",
       "      <td>166713</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539352</th>\n",
       "      <td>52452</td>\n",
       "      <td>52452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539353</th>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539354</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539355</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539356</th>\n",
       "      <td>66402</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539357</th>\n",
       "      <td>4975</td>\n",
       "      <td>4975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539358</th>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539359</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539360</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539361</th>\n",
       "      <td>10618</td>\n",
       "      <td>10618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539362</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539363</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539364</th>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539365</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539366</th>\n",
       "      <td>249066</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539367</th>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539368</th>\n",
       "      <td>420</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539369</th>\n",
       "      <td>525991</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539370 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_gap_before_total  time_gap_before\n",
       "0                          -1               -1\n",
       "1                          65               65\n",
       "2                          -1               -1\n",
       "3                          -1               -1\n",
       "4                          -1               -1\n",
       "5                         763              763\n",
       "6                        2550             2550\n",
       "7                          -1               -1\n",
       "8                          -1               -1\n",
       "9                          24               24\n",
       "10                         -1               -1\n",
       "11                         -1               -1\n",
       "12                         -1               -1\n",
       "13                       6624             6624\n",
       "14                         -1               -1\n",
       "15                         -1               -1\n",
       "16                         -1               -1\n",
       "17                         -1               -1\n",
       "18                       3124             3124\n",
       "19                         -1               -1\n",
       "20                       3196             3196\n",
       "21                         -1               -1\n",
       "22                         -1               -1\n",
       "23                         -1               -1\n",
       "24                         -1               -1\n",
       "25                         -1               -1\n",
       "26                         -1               -1\n",
       "27                         -1               -1\n",
       "28                         -1               -1\n",
       "29                        138              138\n",
       "...                       ...              ...\n",
       "539340                     -1               -1\n",
       "539341                     -1               -1\n",
       "539342                      8                8\n",
       "539343                    164              164\n",
       "539344                     23               23\n",
       "539345                     -1               -1\n",
       "539346                     -1               -1\n",
       "539347                     -1               -1\n",
       "539348                     -1               -1\n",
       "539349                     -1               -1\n",
       "539350                     -1               -1\n",
       "539351                 166713               -1\n",
       "539352                  52452            52452\n",
       "539353                    202              202\n",
       "539354                     -1               -1\n",
       "539355                     -1               -1\n",
       "539356                  66402               -1\n",
       "539357                   4975             4975\n",
       "539358                    119              119\n",
       "539359                     -1               -1\n",
       "539360                     74               74\n",
       "539361                  10618            10618\n",
       "539362                     74               74\n",
       "539363                     -1               -1\n",
       "539364                    221              221\n",
       "539365                     -1               -1\n",
       "539366                 249066               -1\n",
       "539367                    343              343\n",
       "539368                    420              420\n",
       "539369                 525991               -1\n",
       "\n",
       "[539370 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[['time_gap_before_total','time_gap_before']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 想要添加：\n",
    "    该次点击是用户第几次访问这个物品，全局数据"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
