{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户与相关属性的组合特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import load_pickle, dump_pickle, raw_data_path, feature_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_user_feature_feature_click_day(update=True):\n",
    "    data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "\n",
    "    feature_path = feature_data_path + 'user_brand_price_click_day.pkl'\n",
    "    feature_path_1 = feature_data_path + 'user_label_price_click_day.pkl'\n",
    "    feature_path_2 = feature_data_path + 'user_label_brand_click_day.pkl'\n",
    "    if os.path.exists(feature_path) and update == False:\n",
    "        print('found '+feature_path)\n",
    "    else:\n",
    "        print('generating '+feature_path)\n",
    "        user_brand_price_click_day = data.groupby(['user_id', 'day', 'item_brand_id', 'item_price_level']).size(\n",
    "        ).reset_index().rename(columns={0: 'user_brand_price_click_day'})\n",
    "        dump_pickle(user_brand_price_click_day, feature_path)\n",
    "        \n",
    "        user_label_price_click_day = data.groupby(['user_id', 'day', 'category2_label', 'item_price_level']).size(\n",
    "        ).reset_index().rename(columns={0: 'user_label_price_click_day'})\n",
    "        dump_pickle(user_label_price_click_day, feature_path_1)\n",
    "        \n",
    "        user_label_brand_click_day = data.groupby(['user_id', 'day', 'category2_label', 'item_brand_id']).size(\n",
    "        ).reset_index().rename(columns={0: 'user_label_brand_click_day'})\n",
    "        dump_pickle(user_label_brand_click_day, feature_path_2)\n",
    "\n",
    "\n",
    "def add_user_feature_feature_click_day(data):\n",
    "   \n",
    " \n",
    "    feature_path = feature_data_path + 'user_brand_price_click_day.pkl'\n",
    "    feature_path_1 = feature_data_path + 'user_label_price_click_day.pkl'\n",
    "    feature_path_2 = feature_data_path + 'user_label_brand_click_day.pkl'\n",
    "    if not os.path.exists(feature_path):\n",
    "        gen_user_feature_feature_click_day()\n",
    "    feature_click_day = load_pickle(feature_path)\n",
    "    data = pd.merge(data, feature_click_day, 'left',['user_id', 'day', 'item_brand_id', 'item_price_level'])\n",
    "\n",
    "    feature_click_day = load_pickle(feature_path_1)\n",
    "    data = pd.merge(data, feature_click_day, 'left',['user_id', 'day', 'category2_label', 'item_price_level'])\n",
    "    \n",
    "    feature_click_day = load_pickle(feature_path_2)\n",
    "    data = pd.merge(data, feature_click_day, 'left',['user_id', 'day', 'category2_label', 'item_brand_id'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_user_feature_feature_click_all(update=True):\n",
    "    data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "\n",
    "    feature_path = feature_data_path + 'user_brand_price_click_all.pkl'\n",
    "    feature_path_1 = feature_data_path + 'user_label_price_click_all.pkl'\n",
    "    feature_path_2 = feature_data_path + 'user_label_brand_click_all.pkl'\n",
    "    if os.path.exists(feature_path) and update == False:\n",
    "        print('found '+feature_path)\n",
    "    else:\n",
    "        print('generating '+feature_path)\n",
    "        user_brand_price_click_day = data.groupby(['user_id', 'item_brand_id', 'item_price_level']).size(\n",
    "        ).reset_index().rename(columns={0: 'user_brand_price_click_all'})\n",
    "        dump_pickle(user_brand_price_click_day, feature_path)\n",
    "        \n",
    "        user_label_price_click_day = data.groupby(['user_id', 'category2_label', 'item_price_level']).size(\n",
    "        ).reset_index().rename(columns={0: 'user_label_price_click_all'})\n",
    "        dump_pickle(user_label_price_click_day, feature_path_1)\n",
    "        \n",
    "        user_label_brand_click_day = data.groupby(['user_id', 'category2_label', 'item_brand_id']).size(\n",
    "        ).reset_index().rename(columns={0: 'user_label_brand_click_all'})\n",
    "        dump_pickle(user_label_brand_click_day, feature_path_2)\n",
    "\n",
    "\n",
    "def add_user_feature_feature_click_all(data):\n",
    "   \n",
    " \n",
    "    feature_path = feature_data_path + 'user_brand_price_click_all.pkl'\n",
    "    feature_path_1 = feature_data_path + 'user_label_price_click_all.pkl'\n",
    "    feature_path_2 = feature_data_path + 'user_label_brand_click_all.pkl'\n",
    "    if not os.path.exists(feature_path):\n",
    "        gen_user_feature_feature_click_all()\n",
    "    feature_click_day = load_pickle(feature_path)\n",
    "    data = pd.merge(data, feature_click_day, 'left',['user_id', 'item_brand_id', 'item_price_level'])\n",
    "\n",
    "    feature_click_day = load_pickle(feature_path_1)\n",
    "    data = pd.merge(data, feature_click_day, 'left',['user_id', 'category2_label', 'item_price_level'])\n",
    "    \n",
    "    feature_click_day = load_pickle(feature_path_2)\n",
    "    data = pd.merge(data, feature_click_day, 'left',['user_id', 'category2_label', 'item_brand_id'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_user_feature_click_day(update=True):\n",
    "    \"\"\"生成用户对所有分类属性的当天点击量\n",
    "\n",
    "    file_name: user_(feature_id)_click_day.pkl\n",
    "    \n",
    "    features:\n",
    "        'user_item_id_click_day', \n",
    "        'user_item_brand_id_click_day',\n",
    "        'user_item_city_id_click_day', \n",
    "        'user_context_page_id_click_day',\n",
    "        'user_shop_id_click_day',\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "\n",
    "    feature_list=['item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level', \n",
    "                  'item_collected_level', 'item_pv_level',\n",
    "                  'context_page_id', \n",
    "                  'shop_id', 'shop_review_num_level', 'shop_star_level',]\n",
    "\n",
    "    for feature in tqdm(feature_list):\n",
    "        feature_path = feature_data_path + 'user_'+feature+'_click_day.pkl'\n",
    "        if os.path.exists(feature_path) and update == False:\n",
    "            print('found '+feature_path)\n",
    "        else:\n",
    "            print('generating '+feature_path)\n",
    "            user_feature_click_day = data.groupby(['user_id', 'day', feature]).size(\n",
    "            ).reset_index().rename(columns={0: 'user_'+feature+'_click_day'})\n",
    "            dump_pickle(user_feature_click_day, feature_path)\n",
    "\n",
    "\n",
    "def add_user_feature_click_day(data):\n",
    "    \"\"\"添加用户对所有分类属性的当天点击量\n",
    "\n",
    "    join_key: ['user_id', 'feature_id', 'day']\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_list=['item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level', \n",
    "                  'item_collected_level', 'item_pv_level',\n",
    "                  'context_page_id', \n",
    "                  'shop_id', 'shop_review_num_level', 'shop_star_level',]\n",
    "\n",
    "    for feature in tqdm(feature_list):\n",
    "        feature_path = feature_data_path + 'user_'+feature+'_click_day.pkl'\n",
    "        if not os.path.exists(feature_path):\n",
    "            gen_user_feature_click_day()\n",
    "        feature_click_day = load_pickle(feature_path)\n",
    "        data = pd.merge(data, feature_click_day, 'left',\n",
    "                        [feature, 'day', 'user_id'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_user_feature_click_hour(update=True):\n",
    "    \"\"\"生成用户对所有分类属性的当前小时点击量\n",
    "\n",
    "    file_name: user_(feature_id)_click_hour.pkl\n",
    "    \n",
    "    features:\n",
    "        'user_item_id_click_hour',\n",
    "        'user_item_brand_id_click_hour', \n",
    "        'user_context_page_id_click_hour', \n",
    "        'user_shop_id_click_hour',\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "\n",
    "    feature_list=['item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level', \n",
    "                  'item_collected_level', 'item_pv_level',\n",
    "                  'context_page_id', \n",
    "                  'shop_id', 'shop_review_num_level', 'shop_star_level',]\n",
    "\n",
    "    for feature in tqdm(feature_list):\n",
    "        feature_path = feature_data_path + 'user_'+feature+'_click_hour.pkl'\n",
    "        if os.path.exists(feature_path) and update == False:\n",
    "            print('found '+feature_path)\n",
    "        else:\n",
    "            print('generating '+feature_path)\n",
    "            user_feature_click_day = data.groupby(['user_id', 'day', 'hour', feature]).size(\n",
    "            ).reset_index().rename(columns={0: 'user_'+feature+'_click_hour'})\n",
    "            dump_pickle(user_feature_click_day, feature_path)\n",
    "\n",
    "\n",
    "def add_user_feature_click_hour(data):\n",
    "    \"\"\"添加用户对所有分类属性的当天点击统计量\n",
    "\n",
    "    join_key: ['user_id', 'feature_id', 'day', 'hour']\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    feature_list=['item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level', \n",
    "                  'item_collected_level', 'item_pv_level',\n",
    "                  'context_page_id', \n",
    "                  'shop_id', 'shop_review_num_level', 'shop_star_level',]\n",
    "    \n",
    "    for feature in tqdm(feature_list):\n",
    "        feature_path = feature_data_path + 'user_'+feature+'_click_hour.pkl'\n",
    "        if not os.path.exists(feature_path):\n",
    "            gen_user_feature_click_hour()\n",
    "        feature_click_hour = load_pickle(feature_path)\n",
    "        data = pd.merge(data, feature_click_hour, 'left', [\n",
    "                        feature, 'day', 'hour', 'user_id'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成用户对单一特征点击数据的统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_user_feature_click_day_stats(data, feature):\n",
    "    '''生成用户对单一特征点击量的单日统计特征\n",
    "\n",
    "    '''\n",
    "    \n",
    "    user_feature_click_day = pd.DataFrame(data.groupby(\n",
    "        ['user_id', feature, 'day'])['context_timestamp'].count(), )\n",
    "    user_feature_click_day.rename(\n",
    "        columns={'context_timestamp': feature + '_m'}, inplace=True)\n",
    "    user_feature_click_day.reset_index(inplace=True)\n",
    "    user_feature_click_day_mean = pd.DataFrame(user_feature_click_day.groupby(['user_id'])[\n",
    "        feature+'_m'].mean()).rename(columns={feature+'_m': 'user_' + feature + '_click_day_mean'}).reset_index()\n",
    "    user_feature_click_day_max = pd.DataFrame(user_feature_click_day.groupby(['user_id'])[\n",
    "        feature+'_m'].max()).rename(columns={feature+'_m': 'user_' + feature + '_click_day_max'}).reset_index()\n",
    "    user_feature_click_day_min = pd.DataFrame(user_feature_click_day.groupby(['user_id'])[\n",
    "        feature+'_m'].min()).rename(columns={feature+'_m': 'user_' + feature + '_click_day_min'}).reset_index()\n",
    "\n",
    "    data = pd.merge(data, user_feature_click_day_mean,\n",
    "                    how='left', on='user_id')\n",
    "    data = pd.merge(data, user_feature_click_day_max, how='left', on='user_id')\n",
    "    data = pd.merge(data, user_feature_click_day_min, how='left', on='user_id')\n",
    "    return data\n",
    "\n",
    "\n",
    "def gen_user_click_stats(update=True):\n",
    "    \"\"\"生成用户点击数据的统计特征\n",
    "    \n",
    "    file_name: user_feature_click_stats.pkl\n",
    "    \n",
    "    example:\n",
    "        user_item_id_click_day_mean 用户对一个 item 平均每天点击多少次\n",
    "        user_item_id_click_day_max 用户对一个 item 最多单日点击次数\n",
    "    \n",
    "    features:\n",
    "        'user_item_id_click_day_mean', 'user_item_id_click_day_min', 'user_item_id_click_day_max', \n",
    "        'user_item_brand_id_click_day_mean', 'user_item_brand_id_click_day_min', 'user_item_brand_id_click_day_max',\n",
    "        'user_shop_id_click_day_mean', 'user_shop_id_click_day_min', 'user_shop_id_click_day_max',\n",
    "        'user_category2_label_click_day_mean', 'user_category2_label_click_day_min', 'user_category2_label_click_day_max',\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "    feature_path = feature_data_path + 'user_feature_click_stats.pkl'\n",
    "\n",
    "    if os.path.exists(feature_path) and update == False:\n",
    "        print('found ' + feature_path)\n",
    "    else:\n",
    "        print('generating ' + feature_path)\n",
    "        \n",
    "        feature_names = ['user_item_id_click_day_mean', 'user_item_id_click_day_min', 'user_item_id_click_day_max',\n",
    "                         'user_item_brand_id_click_day_mean', 'user_item_brand_id_click_day_min', 'user_item_brand_id_click_day_max',\n",
    "                         'user_shop_id_click_day_mean', 'user_shop_id_click_day_min', 'user_shop_id_click_day_max',\n",
    "                         'user_category2_label_click_day_mean', 'user_category2_label_click_day_min', 'user_category2_label_click_day_max',\n",
    "                         ]\n",
    "\n",
    "        stats_feature = ['item_id', 'item_brand_id', 'shop_id', 'category2_label']\n",
    "        for feature in tqdm(stats_feature):\n",
    "            data = gen_user_feature_click_day_stats(data, feature)\n",
    "\n",
    "        # 每个用户只保留一条记录\n",
    "        data = data[feature_names + ['user_id']].drop_duplicates(['user_id'])\n",
    "        dump_pickle(data, feature_path)\n",
    "\n",
    "\n",
    "def add_user_click_stats(data,):\n",
    "    \"\"\"添加用户点击数据的统计特征\n",
    "\n",
    "    join_key: ['user_id',]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    feature_path = feature_data_path + 'user_feature_click_stats.pkl'\n",
    "    if not os.path.exists(feature_path):\n",
    "        gen_user_click_stats()\n",
    "    user_click_stats = load_pickle(feature_path)\n",
    "    data = pd.merge(data, user_click_stats, 'left', 'user_id')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_brand_price_click_all.pkl\n"
     ]
    }
   ],
   "source": [
    "if __name__ =='__main__':\n",
    "    all_data = load_pickle(raw_data_path + 'all_data.pkl')  \n",
    "    all_data = add_user_feature_click_day(all_data)\n",
    "    all_data = add_user_feature_click_hour(all_data)\n",
    "    all_data = add_user_click_stats(all_data)\n",
    "    all_data = add_user_feature_feature_click_day(all_data)\n",
    "    all_data = add_user_feature_feature_click_all(all_data)\n",
    "    all_data.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
