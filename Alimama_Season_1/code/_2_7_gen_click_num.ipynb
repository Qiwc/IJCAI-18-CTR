{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from utils import raw_data_path, feature_data_path,result_path,cache_pkl_path,dump_pickle,load_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算每天的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_feature_click_day(update=True):\n",
    "    '''\n",
    "    计算feature=['user_id', 'item_id', 'item_brand_id', 'shop_id', 'user_gender_id', 'context_page_id',\n",
    "                        'user_occupation_id', 'user_age_level']的点击量\n",
    "    计算的是每天的\n",
    "\n",
    "    文件名：[feature]_clicks_day.pkl\n",
    "    '''\n",
    "\n",
    "    all_data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "\n",
    "    for feature in tqdm(['user_id', 'user_occupation_id', 'user_age_level', 'user_gender_id', 'user_star_level',\n",
    "                         'item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level', \n",
    "                         'item_collected_level', 'item_pv_level',\n",
    "                         'context_page_id', \n",
    "                         'shop_id', 'shop_review_num_level', 'shop_star_level',]):\n",
    "\n",
    "        feature_path = feature_data_path+feature+'_clicks_day.pkl'  # 要存放的目录\n",
    "        if os.path.exists(feature_path) and update == False:\n",
    "            print('found ' + feature_path)\n",
    "        else:\n",
    "            print('generating ' + feature_path)\n",
    "            feature_click_day = pd.DataFrame(all_data.groupby(['day', feature]).size(\n",
    "            )).reset_index().rename(columns={0: feature + '_click_day'})\n",
    "            dump_pickle(feature_click_day, feature_path)\n",
    "\n",
    "\n",
    "def add_feature_click_day(all_data):\n",
    "    '''\n",
    "    向总体数据添加特征\n",
    "    feature=['user_id', 'item_id', 'item_brand_id', 'shop_id', 'user_gender_id', 'context_page_id',\n",
    "                        'user_occupation_id', 'user_age_level']\n",
    "    拼接键[feature, 'day']\n",
    "    '''\n",
    "\n",
    "    for feature in tqdm(['user_id', 'user_occupation_id', 'user_age_level', 'user_gender_id', 'user_star_level',\n",
    "                         'item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level', \n",
    "                         'item_collected_level', 'item_pv_level',\n",
    "                         'context_page_id', \n",
    "                         'shop_id', 'shop_review_num_level', 'shop_star_level',]):\n",
    "        feature_path = feature_data_path + feature + '_clicks_day.pkl'\n",
    "        if not os.path.exists(feature_path):\n",
    "            gen_feature_click_day()\n",
    "        feature_click_day = load_pickle(feature_path)\n",
    "        all_data = pd.merge(all_data, feature_click_day,\n",
    "                            how='left', on=[feature, 'day'])\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算每天每小时的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_feature_click_day_hour(update=True):\n",
    "    '''\n",
    "    计算feature=['user_id', 'item_id', 'item_brand_id', 'shop_id', 'user_gender_id', 'context_page_id',\n",
    "                        'user_occupation_id', 'user_age_level']的点击量\n",
    "    计算的是每天每小时\n",
    "\n",
    "    文件名：[feature]_click_hour.pkl\n",
    "    '''\n",
    "\n",
    "    all_data = load_pickle(raw_data_path+'all_data.pkl')\n",
    "    for feature in tqdm(['user_id', 'user_occupation_id', 'user_age_level', 'user_gender_id', 'user_star_level',\n",
    "                         'item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level', \n",
    "                         'item_collected_level', 'item_pv_level',\n",
    "                         'context_page_id', \n",
    "                         'shop_id', 'shop_review_num_level', 'shop_star_level',]):\n",
    "        feature_path = feature_data_path+feature+'_click_day_hour.pkl'  # 要存放的目录\n",
    "        if os.path.exists(feature_path) and update == False:\n",
    "            print('found ' + feature_path)\n",
    "        else:\n",
    "            print('generating ' + feature_path)\n",
    "            feature_click_day_hour = all_data.groupby([feature, 'day', 'hour']).size(\n",
    "            ).reset_index().rename(columns={0: feature+'_click_hour'})\n",
    "            dump_pickle(feature_click_day_hour, feature_path)  # 存储\n",
    "\n",
    "\n",
    "def add_feature_click_day_hour(all_data):\n",
    "    '''\n",
    "    向总体数据添加特征\n",
    "    feature=['user_id', 'item_id', 'item_brand_id', 'shop_id', 'user_gender_id', 'context_page_id',\n",
    "                        'user_occupation_id', 'user_age_level', 'category2_label']\n",
    "    拼接键[feature, 'day']\n",
    "    '''\n",
    "    for feature in tqdm(['user_id', 'user_occupation_id', 'user_age_level', 'user_gender_id', 'user_star_level',\n",
    "                         'item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level', \n",
    "                         'item_collected_level', 'item_pv_level',\n",
    "                         'context_page_id', \n",
    "                         'shop_id', 'shop_review_num_level', 'shop_star_level',]):\n",
    "        feature_path = feature_data_path+feature+'_click_day_hour.pkl'\n",
    "        if not os.path.exists(feature_path):\n",
    "            gen_feature_click_day_hour()\n",
    "        feature_click_day_hour = load_pickle(feature_path)\n",
    "        all_data = pd.merge(all_data, feature_click_day_hour,\n",
    "                            how='left', on=[feature, 'day', 'hour'])\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算每小时的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_feature_click_hour(update=True):\n",
    "    '''\n",
    "    计算feature=['user_id', 'item_id', 'item_brand_id', 'shop_id', 'user_gender_id', 'context_page_id',\n",
    "                        'user_occupation_id', 'user_age_level']的点击量\n",
    "    计算的是每天每小时\n",
    "\n",
    "    文件名：[feature]_click_hour.pkl\n",
    "    '''\n",
    "\n",
    "    all_data = load_pickle(raw_data_path+'all_data.pkl')\n",
    "    for feature in tqdm(['user_id', 'user_occupation_id', 'user_age_level', 'user_gender_id', 'user_star_level',\n",
    "                         'item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level', \n",
    "                         'item_collected_level', 'item_pv_level',\n",
    "                         'context_page_id', \n",
    "                         'shop_id', 'shop_review_num_level', 'shop_star_level',]):\n",
    "        feature_path = feature_data_path+feature+'_click_hour.pkl'  # 要存放的目录\n",
    "        if os.path.exists(feature_path) and update == False:\n",
    "            print('found ' + feature_path)\n",
    "        else:\n",
    "            print('generating ' + feature_path)\n",
    "            feature_click_hour = all_data.groupby([feature, 'hour']).size(\n",
    "            ).reset_index().rename(columns={0: feature+'_click_hour'})\n",
    "            dump_pickle(feature_click_hour, feature_path)  # 存储\n",
    "\n",
    "\n",
    "def add_feature_click_hour(all_data):\n",
    "    '''\n",
    "    向总体数据添加特征\n",
    "    feature=['user_id', 'item_id', 'item_brand_id', 'shop_id', 'user_gender_id', 'context_page_id',\n",
    "                        'user_occupation_id', 'user_age_level', 'category2_label']\n",
    "    拼接键[feature, 'day']\n",
    "    '''\n",
    "    for feature in tqdm(['user_id', 'user_occupation_id', 'user_age_level', 'user_gender_id', 'user_star_level',\n",
    "                         'item_id', 'item_brand_id', 'item_city_id', 'category2_label','item_price_level','item_sales_level', \n",
    "                         'item_collected_level', 'item_pv_level',\n",
    "                         'context_page_id', \n",
    "                         'shop_id', 'shop_review_num_level', 'shop_star_level',]):\n",
    "        feature_path = feature_data_path+feature+'_click_hour.pkl'\n",
    "        if not os.path.exists(feature_path):\n",
    "            gen_feature_click_hour()\n",
    "        feature_click_hour = load_pickle(feature_path)\n",
    "        all_data = pd.merge(all_data, feature_click_hour,\n",
    "                            how='left', on=[feature, 'hour'])\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算历史的，考虑只计算前一天的 放弃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_feature_click_history(update=True):\n",
    "    '''\n",
    "    计算feature=['user_id', 'item_id', 'item_brand_id', 'shop_id', 'user_gender_id', 'context_page_id',\n",
    "                        'user_occupation_id', 'user_age_level']的点击量\n",
    "    计算的是每天的\n",
    "\n",
    "    文件名：[feature]_click_history.pkl\n",
    "    \n",
    "    features:\n",
    "        'user_id_click_history', 'item_id_click_history',\n",
    "       'item_brand_id_click_history', 'shop_id_click_history',\n",
    "       'user_gender_id_click_history', 'context_page_id_click_history',\n",
    "       'user_occupation_id_click_history', 'user_age_level_click_history'\n",
    "    \n",
    "    '''\n",
    "\n",
    "    all_data = load_pickle(raw_data_path+'all_data.pkl')    \n",
    "    for feature in tqdm(['user_id', 'item_id', 'item_brand_id', 'shop_id', 'user_gender_id', 'context_page_id',\n",
    "                        'user_occupation_id', 'user_age_level', 'category2_label', 'item_sales_level', 'item_price_level', 'user_star_level']):        \n",
    "        feature_path = feature_data_path+feature+'_click_history.pkl' #要存放的目录\n",
    "        if os.path.exists(feature_path) and update == False:\n",
    "            print('found ' + feature_path)\n",
    "        else:\n",
    "            print('generating ' + feature_path)        \n",
    "            data = pd.DataFrame()\n",
    "            for day in range(18,26):               \n",
    "                now_data = all_data[all_data['day'] <= day]            \n",
    "                feature_click_history = now_data.groupby([feature]).size().reset_index().rename(columns={0: feature+'_click_history'})       \n",
    "                feature_click_history['day'] = day\n",
    "                data = data.append(feature_click_history)\n",
    "            dump_pickle(data,feature_path)  #存储\n",
    "\n",
    "            \n",
    "def add_feature_click_history(all_data):\n",
    "    '''\n",
    "    向总体数据添加特征\n",
    "    feature=['user_id', 'item_id', 'item_brand_id', 'shop_id', 'user_gender_id', 'context_page_id',\n",
    "                        'user_occupation_id', 'user_age_level', 'category2_label']\n",
    "    拼接键[feature, 'day']\n",
    "    '''\n",
    "    \n",
    "    for feature in tqdm(['user_id', 'item_id', 'item_brand_id', 'shop_id', 'user_gender_id', 'context_page_id',\n",
    "                        'user_occupation_id', 'user_age_level', 'category2_label', 'item_sales_level', 'item_price_level', 'user_star_level']):  \n",
    "        feature_path = feature_data_path+feature+'_click_history.pkl'\n",
    "        if not os.path.exists(feature_path):\n",
    "            gen_feature_click_history()\n",
    "        Clicks_data = load_pickle(feature_path)\n",
    "        all_data = pd.merge(all_data, Clicks_data, how='left', on=[feature, 'day'])\n",
    "    \n",
    "    return all_data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/17 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_id_clicks_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|████▉                                                                              | 1/17 [00:00<00:05,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_occupation_id_clicks_day.pkl\n",
      "generating ../features/user_age_level_clicks_day.pkl\n",
      "generating ../features/user_gender_id_clicks_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|███████████████████▌                                                               | 4/17 [00:00<00:01,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_star_level_clicks_day.pkl\n",
      "generating ../features/item_id_clicks_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|█████████████████████████████▎                                                     | 6/17 [00:00<00:01,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/item_brand_id_clicks_day.pkl\n",
      "generating ../features/item_city_id_clicks_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|███████████████████████████████████████                                            | 8/17 [00:00<00:00, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/category2_label_clicks_day.pkl\n",
      "generating ../features/item_price_level_clicks_day.pkl\n",
      "generating ../features/item_sales_level_clicks_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|█████████████████████████████████████████████████████                             | 11/17 [00:00<00:00, 13.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/item_collected_level_clicks_day.pkl\n",
      "generating ../features/item_pv_level_clicks_day.pkl\n",
      "generating ../features/context_page_id_clicks_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|███████████████████████████████████████████████████████████████████▌              | 14/17 [00:00<00:00, 14.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/shop_id_clicks_day.pkl\n",
      "generating ../features/shop_review_num_level_clicks_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▏    | 16/17 [00:01<00:00, 14.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/shop_star_level_clicks_day.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:06<00:00,  2.63it/s]\n",
      "  0%|                                                                                           | 0/17 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_id_click_hour.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|████▉                                                                              | 1/17 [00:00<00:06,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_occupation_id_click_hour.pkl\n",
      "generating ../features/user_age_level_click_hour.pkl\n",
      "generating ../features/user_gender_id_click_hour.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|███████████████████▌                                                               | 4/17 [00:00<00:01,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/user_star_level_click_hour.pkl\n",
      "generating ../features/item_id_click_hour.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|█████████████████████████████▎                                                     | 6/17 [00:00<00:01,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/item_brand_id_click_hour.pkl\n",
      "generating ../features/item_city_id_click_hour.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|███████████████████████████████████████                                            | 8/17 [00:00<00:00, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/category2_label_click_hour.pkl\n",
      "generating ../features/item_price_level_click_hour.pkl\n",
      "generating ../features/item_sales_level_click_hour.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|█████████████████████████████████████████████████████                             | 11/17 [00:00<00:00, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/item_collected_level_click_hour.pkl\n",
      "generating ../features/item_pv_level_click_hour.pkl\n",
      "generating ../features/context_page_id_click_hour.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|███████████████████████████████████████████████████████████████████▌              | 14/17 [00:01<00:00, 13.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/shop_id_click_hour.pkl\n",
      "generating ../features/shop_review_num_level_click_hour.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▏    | 16/17 [00:01<00:00, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ../features/shop_star_level_click_hour.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|█████████████████████████████████████████████████████████▉                        | 12/17 [00:06<00:02,  1.96it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ =='__main__':\n",
    "    \n",
    "\n",
    "    \n",
    "    all_data = load_pickle(raw_data_path + 'all_data.pkl')\n",
    "    all_data = add_feature_click_day(all_data)\n",
    "    all_data = add_feature_click_hour(all_data)\n",
    "    all_data = add_feature_click_day_hour(all_data)\n",
    "    \n",
    "    print(all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
