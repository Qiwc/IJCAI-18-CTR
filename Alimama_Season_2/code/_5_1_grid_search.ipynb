{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import time\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import load_pickle, dump_pickle, get_feature_value, feature_spearmanr, feature_target_spearmanr, addCrossFeature, calibration\n",
    "from utils import raw_data_path, feature_data_path, cache_pkl_path, analyse\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomCV(data,):    \n",
    "    fold_index_train = data[(data.hour < 11) & (data.hour > 1)].index\n",
    "    fold_index_test = data[data.hour >= 11].index\n",
    "    yield fold_index_train, fold_index_test\n",
    "    \n",
    "    \n",
    "def CustomCV_6_7(data,):    \n",
    "    fold_index_train = data[((data.day == 7) & (data.hour < 11)) | (data.day == 6)].index\n",
    "    fold_index_test = data[(data.day == 7) & (data.hour >= 11)].index\n",
    "    yield fold_index_train, fold_index_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_path = feature_data_path + 'all_data_all_features.pkl'\n",
    "all_data = load_pickle(all_data_path)\n",
    "\n",
    "target = 'is_trade'\n",
    "\n",
    "features = load_pickle('all_features_day_7.pkl')\n",
    "categorical_feature = load_pickle('categorical_feature.pkl')\n",
    "\n",
    "\n",
    "len(features), len(categorical_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 6 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qwc/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1038: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['item_property_topic_k_10', 'user_category2_label_click_rank_day', 'user_category3_label_click_rank_day', 'user_click_rank_day', 'user_gender_id', 'user_item_brand_id_click_rank_day', 'user_item_id_click_rank_day', 'user_occupation_id', 'user_shop_id_click_rank_day']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/home/qwc/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1038: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['item_property_topic_k_10', 'user_category2_label_click_rank_day', 'user_category3_label_click_rank_day', 'user_click_rank_day', 'user_gender_id', 'user_item_brand_id_click_rank_day', 'user_item_id_click_rank_day', 'user_occupation_id', 'user_shop_id_click_rank_day']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/home/qwc/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1038: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['item_property_topic_k_10', 'user_category2_label_click_rank_day', 'user_category3_label_click_rank_day', 'user_click_rank_day', 'user_gender_id', 'user_item_brand_id_click_rank_day', 'user_item_id_click_rank_day', 'user_occupation_id', 'user_shop_id_click_rank_day']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qwc/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1038: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['item_property_topic_k_10', 'user_category2_label_click_rank_day', 'user_category3_label_click_rank_day', 'user_click_rank_day', 'user_gender_id', 'user_item_brand_id_click_rank_day', 'user_item_id_click_rank_day', 'user_occupation_id', 'user_shop_id_click_rank_day']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.182822\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.182822\n",
      "[50]\tvalid_0's binary_logloss: 0.182822\n",
      "[100]\tvalid_0's binary_logloss: 0.166324\n",
      "[50]\tvalid_0's binary_logloss: 0.182865\n",
      "[100]\tvalid_0's binary_logloss: 0.166323\n",
      "[150]\tvalid_0's binary_logloss: 0.164455\n",
      "[100]\tvalid_0's binary_logloss: 0.166302\n",
      "[150]\tvalid_0's binary_logloss: 0.164455\n",
      "[100]\tvalid_0's binary_logloss: 0.166314\n",
      "[150]\tvalid_0's binary_logloss: 0.164446\n",
      "[200]\tvalid_0's binary_logloss: 0.163694\n",
      "[200]\tvalid_0's binary_logloss: 0.163675\n",
      "[150]\tvalid_0's binary_logloss: 0.16447\n",
      "[250]\tvalid_0's binary_logloss: 0.163196\n",
      "[200]\tvalid_0's binary_logloss: 0.163658\n",
      "[250]\tvalid_0's binary_logloss: 0.163198\n",
      "[200]\tvalid_0's binary_logloss: 0.163687\n",
      "[300]\tvalid_0's binary_logloss: 0.16285\n",
      "[250]\tvalid_0's binary_logloss: 0.163156\n",
      "[300]\tvalid_0's binary_logloss: 0.162862\n",
      "[250]\tvalid_0's binary_logloss: 0.163207\n",
      "[300]\tvalid_0's binary_logloss: 0.162822\n",
      "[350]\tvalid_0's binary_logloss: 0.1626\n",
      "[350]\tvalid_0's binary_logloss: 0.162628\n",
      "[300]\tvalid_0's binary_logloss: 0.162926\n",
      "[350]\tvalid_0's binary_logloss: 0.162579\n",
      "[400]\tvalid_0's binary_logloss: 0.162432\n",
      "[400]\tvalid_0's binary_logloss: 0.162466\n",
      "[350]\tvalid_0's binary_logloss: 0.162665\n",
      "[400]\tvalid_0's binary_logloss: 0.1624\n",
      "[450]\tvalid_0's binary_logloss: 0.162299\n",
      "[450]\tvalid_0's binary_logloss: 0.162354\n",
      "[450]\tvalid_0's binary_logloss: 0.162284\n",
      "[400]\tvalid_0's binary_logloss: 0.162471\n",
      "[500]\tvalid_0's binary_logloss: 0.162186\n",
      "[500]\tvalid_0's binary_logloss: 0.162264\n",
      "[500]\tvalid_0's binary_logloss: 0.162188\n",
      "[550]\tvalid_0's binary_logloss: 0.162073\n",
      "[450]\tvalid_0's binary_logloss: 0.162346\n",
      "[550]\tvalid_0's binary_logloss: 0.162141\n",
      "[600]\tvalid_0's binary_logloss: 0.161995\n",
      "[550]\tvalid_0's binary_logloss: 0.162081\n",
      "[500]\tvalid_0's binary_logloss: 0.162222\n",
      "[600]\tvalid_0's binary_logloss: 0.162055\n",
      "[650]\tvalid_0's binary_logloss: 0.161923\n",
      "[600]\tvalid_0's binary_logloss: 0.161988\n",
      "[550]\tvalid_0's binary_logloss: 0.162106\n",
      "[650]\tvalid_0's binary_logloss: 0.161986\n",
      "[700]\tvalid_0's binary_logloss: 0.161852\n",
      "[650]\tvalid_0's binary_logloss: 0.161906\n",
      "[600]\tvalid_0's binary_logloss: 0.162038\n",
      "[700]\tvalid_0's binary_logloss: 0.161919\n",
      "[750]\tvalid_0's binary_logloss: 0.161792\n",
      "[700]\tvalid_0's binary_logloss: 0.161852\n",
      "[650]\tvalid_0's binary_logloss: 0.161952\n",
      "[750]\tvalid_0's binary_logloss: 0.161852\n",
      "[750]\tvalid_0's binary_logloss: 0.161774\n",
      "[800]\tvalid_0's binary_logloss: 0.161739\n",
      "[700]\tvalid_0's binary_logloss: 0.16189\n",
      "[800]\tvalid_0's binary_logloss: 0.161798\n",
      "[800]\tvalid_0's binary_logloss: 0.161711\n",
      "[750]\tvalid_0's binary_logloss: 0.161833\n",
      "[850]\tvalid_0's binary_logloss: 0.161689\n",
      "[850]\tvalid_0's binary_logloss: 0.161748\n",
      "[850]\tvalid_0's binary_logloss: 0.161667\n",
      "[800]\tvalid_0's binary_logloss: 0.161773\n",
      "[900]\tvalid_0's binary_logloss: 0.16165\n",
      "[900]\tvalid_0's binary_logloss: 0.161623\n",
      "[900]\tvalid_0's binary_logloss: 0.161702\n",
      "[850]\tvalid_0's binary_logloss: 0.161735\n",
      "[950]\tvalid_0's binary_logloss: 0.161632\n",
      "[950]\tvalid_0's binary_logloss: 0.161606\n",
      "[900]\tvalid_0's binary_logloss: 0.161709\n",
      "[950]\tvalid_0's binary_logloss: 0.161679\n",
      "[1000]\tvalid_0's binary_logloss: 0.161586\n",
      "[1000]\tvalid_0's binary_logloss: 0.161565\n",
      "[950]\tvalid_0's binary_logloss: 0.161687\n",
      "[1000]\tvalid_0's binary_logloss: 0.161609\n",
      "[1050]\tvalid_0's binary_logloss: 0.161538\n",
      "[1050]\tvalid_0's binary_logloss: 0.161562\n",
      "[1000]\tvalid_0's binary_logloss: 0.161636\n",
      "[1050]\tvalid_0's binary_logloss: 0.161573\n",
      "[1100]\tvalid_0's binary_logloss: 0.161511\n",
      "[1050]\tvalid_0's binary_logloss: 0.161614\n",
      "[1100]\tvalid_0's binary_logloss: 0.161533\n",
      "[1100]\tvalid_0's binary_logloss: 0.161556\n",
      "[1150]\tvalid_0's binary_logloss: 0.16149\n",
      "[1100]\tvalid_0's binary_logloss: 0.161574\n",
      "[1150]\tvalid_0's binary_logloss: 0.161518\n",
      "[1200]\tvalid_0's binary_logloss: 0.161471\n",
      "[1150]\tvalid_0's binary_logloss: 0.16156\n",
      "[1150]\tvalid_0's binary_logloss: 0.161539\n",
      "[1200]\tvalid_0's binary_logloss: 0.161498\n",
      "[1250]\tvalid_0's binary_logloss: 0.161459\n",
      "[1200]\tvalid_0's binary_logloss: 0.161547\n",
      "[1200]\tvalid_0's binary_logloss: 0.161521\n",
      "[1250]\tvalid_0's binary_logloss: 0.161494\n",
      "[1300]\tvalid_0's binary_logloss: 0.161461\n",
      "[1250]\tvalid_0's binary_logloss: 0.161535\n",
      "[1250]\tvalid_0's binary_logloss: 0.161515\n",
      "[1300]\tvalid_0's binary_logloss: 0.161497\n",
      "[1350]\tvalid_0's binary_logloss: 0.161455\n",
      "[1300]\tvalid_0's binary_logloss: 0.161544\n",
      "[1300]\tvalid_0's binary_logloss: 0.161514\n",
      "[1400]\tvalid_0's binary_logloss: 0.161443\n",
      "[1350]\tvalid_0's binary_logloss: 0.161495\n",
      "[1350]\tvalid_0's binary_logloss: 0.161524\n",
      "[1450]\tvalid_0's binary_logloss: 0.161441\n",
      "[1350]\tvalid_0's binary_logloss: 0.161505\n",
      "[1400]\tvalid_0's binary_logloss: 0.16151\n",
      "[1400]\tvalid_0's binary_logloss: 0.161477\n",
      "[1500]\tvalid_0's binary_logloss: 0.161419\n",
      "[1450]\tvalid_0's binary_logloss: 0.161523\n",
      "[1400]\tvalid_0's binary_logloss: 0.161489\n",
      "[1450]\tvalid_0's binary_logloss: 0.161483\n",
      "[1550]\tvalid_0's binary_logloss: 0.161421\n",
      "[1500]\tvalid_0's binary_logloss: 0.161508\n",
      "[1450]\tvalid_0's binary_logloss: 0.161497\n",
      "[1500]\tvalid_0's binary_logloss: 0.161476\n",
      "[1600]\tvalid_0's binary_logloss: 0.161414\n",
      "[1550]\tvalid_0's binary_logloss: 0.161491\n",
      "[1500]\tvalid_0's binary_logloss: 0.161481\n",
      "[1550]\tvalid_0's binary_logloss: 0.161474\n",
      "[1650]\tvalid_0's binary_logloss: 0.161397\n",
      "[1600]\tvalid_0's binary_logloss: 0.161477\n",
      "[1550]\tvalid_0's binary_logloss: 0.161473\n",
      "[1600]\tvalid_0's binary_logloss: 0.161471\n",
      "[1700]\tvalid_0's binary_logloss: 0.161403\n",
      "[1650]\tvalid_0's binary_logloss: 0.161471\n",
      "[1600]\tvalid_0's binary_logloss: 0.161474\n",
      "[1650]\tvalid_0's binary_logloss: 0.16146\n",
      "[1750]\tvalid_0's binary_logloss: 0.161386\n",
      "[1700]\tvalid_0's binary_logloss: 0.161454\n",
      "[1650]\tvalid_0's binary_logloss: 0.161468\n",
      "[1700]\tvalid_0's binary_logloss: 0.161457\n",
      "[1800]\tvalid_0's binary_logloss: 0.161393\n",
      "[1750]\tvalid_0's binary_logloss: 0.161449\n",
      "[1700]\tvalid_0's binary_logloss: 0.161458\n",
      "[1750]\tvalid_0's binary_logloss: 0.161446\n",
      "[1850]\tvalid_0's binary_logloss: 0.16137\n",
      "[1800]\tvalid_0's binary_logloss: 0.161448\n",
      "[1750]\tvalid_0's binary_logloss: 0.161459\n",
      "[1800]\tvalid_0's binary_logloss: 0.161449\n",
      "[1900]\tvalid_0's binary_logloss: 0.161376\n",
      "[1850]\tvalid_0's binary_logloss: 0.161437\n",
      "[1800]\tvalid_0's binary_logloss: 0.161463\n",
      "[1850]\tvalid_0's binary_logloss: 0.161432\n",
      "[1950]\tvalid_0's binary_logloss: 0.161385\n",
      "[1900]\tvalid_0's binary_logloss: 0.16144\n",
      "[1850]\tvalid_0's binary_logloss: 0.16144\n",
      "[1900]\tvalid_0's binary_logloss: 0.161448\n",
      "[2000]\tvalid_0's binary_logloss: 0.16137\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1993]\tvalid_0's binary_logloss: 0.161364\n",
      "[1950]\tvalid_0's binary_logloss: 0.161435\n",
      "[1900]\tvalid_0's binary_logloss: 0.161438\n",
      "[1950]\tvalid_0's binary_logloss: 0.161453\n",
      "[2000]\tvalid_0's binary_logloss: 0.161425\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1993]\tvalid_0's binary_logloss: 0.161418\n",
      "[1950]\tvalid_0's binary_logloss: 0.161455\n",
      "[2000]\tvalid_0's binary_logloss: 0.161444\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1848]\tvalid_0's binary_logloss: 0.161431\n",
      "[2000]\tvalid_0's binary_logloss: 0.161435\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1994]\tvalid_0's binary_logloss: 0.161431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qwc/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1038: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['item_property_topic_k_10', 'user_category2_label_click_rank_day', 'user_category3_label_click_rank_day', 'user_click_rank_day', 'user_gender_id', 'user_item_brand_id_click_rank_day', 'user_item_id_click_rank_day', 'user_occupation_id', 'user_shop_id_click_rank_day']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/home/qwc/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1038: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['item_property_topic_k_10', 'user_category2_label_click_rank_day', 'user_category3_label_click_rank_day', 'user_click_rank_day', 'user_gender_id', 'user_item_brand_id_click_rank_day', 'user_item_id_click_rank_day', 'user_occupation_id', 'user_shop_id_click_rank_day']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.182865\n",
      "[100]\tvalid_0's binary_logloss: 0.166314\n",
      "[50]\tvalid_0's binary_logloss: 0.182865\n",
      "[150]\tvalid_0's binary_logloss: 0.164473\n",
      "[100]\tvalid_0's binary_logloss: 0.166314\n",
      "[200]\tvalid_0's binary_logloss: 0.163699\n",
      "[150]\tvalid_0's binary_logloss: 0.164461\n",
      "[250]\tvalid_0's binary_logloss: 0.163202\n",
      "[200]\tvalid_0's binary_logloss: 0.163698\n",
      "[300]\tvalid_0's binary_logloss: 0.162889\n",
      "[250]\tvalid_0's binary_logloss: 0.163224\n",
      "[350]\tvalid_0's binary_logloss: 0.162631\n",
      "[300]\tvalid_0's binary_logloss: 0.162903\n",
      "[400]\tvalid_0's binary_logloss: 0.162468\n",
      "[350]\tvalid_0's binary_logloss: 0.162655\n",
      "[450]\tvalid_0's binary_logloss: 0.162335\n",
      "[400]\tvalid_0's binary_logloss: 0.162485\n",
      "[500]\tvalid_0's binary_logloss: 0.162236\n",
      "[450]\tvalid_0's binary_logloss: 0.162371\n",
      "[550]\tvalid_0's binary_logloss: 0.162109\n",
      "[500]\tvalid_0's binary_logloss: 0.162267\n",
      "[600]\tvalid_0's binary_logloss: 0.162014\n",
      "[550]\tvalid_0's binary_logloss: 0.162142\n",
      "[650]\tvalid_0's binary_logloss: 0.161945\n",
      "[600]\tvalid_0's binary_logloss: 0.162044\n",
      "[700]\tvalid_0's binary_logloss: 0.161865\n",
      "[650]\tvalid_0's binary_logloss: 0.161979\n",
      "[750]\tvalid_0's binary_logloss: 0.161797\n",
      "[700]\tvalid_0's binary_logloss: 0.161929\n",
      "[800]\tvalid_0's binary_logloss: 0.161736\n",
      "[750]\tvalid_0's binary_logloss: 0.161847\n",
      "[850]\tvalid_0's binary_logloss: 0.161704\n",
      "[800]\tvalid_0's binary_logloss: 0.161797\n",
      "[900]\tvalid_0's binary_logloss: 0.161672\n",
      "[850]\tvalid_0's binary_logloss: 0.161756\n",
      "[950]\tvalid_0's binary_logloss: 0.161674\n",
      "[900]\tvalid_0's binary_logloss: 0.161718\n",
      "[1000]\tvalid_0's binary_logloss: 0.16164\n",
      "[950]\tvalid_0's binary_logloss: 0.161707\n",
      "[1050]\tvalid_0's binary_logloss: 0.161623\n",
      "[1000]\tvalid_0's binary_logloss: 0.161663\n",
      "[1100]\tvalid_0's binary_logloss: 0.161598\n",
      "[1050]\tvalid_0's binary_logloss: 0.161632\n",
      "[1150]\tvalid_0's binary_logloss: 0.161593\n",
      "[1100]\tvalid_0's binary_logloss: 0.161598\n",
      "[1200]\tvalid_0's binary_logloss: 0.161574\n",
      "[1150]\tvalid_0's binary_logloss: 0.16159\n",
      "[1250]\tvalid_0's binary_logloss: 0.161575\n",
      "[1200]\tvalid_0's binary_logloss: 0.161571\n",
      "[1300]\tvalid_0's binary_logloss: 0.161577\n",
      "[1250]\tvalid_0's binary_logloss: 0.161568\n",
      "[1350]\tvalid_0's binary_logloss: 0.161574\n",
      "[1300]\tvalid_0's binary_logloss: 0.161575\n",
      "[1350]\tvalid_0's binary_logloss: 0.161555\n",
      "[1400]\tvalid_0's binary_logloss: 0.16157\n",
      "[1400]\tvalid_0's binary_logloss: 0.161544\n",
      "[1450]\tvalid_0's binary_logloss: 0.161556\n",
      "[1450]\tvalid_0's binary_logloss: 0.161533\n",
      "[1500]\tvalid_0's binary_logloss: 0.161541\n",
      "[1500]\tvalid_0's binary_logloss: 0.161522\n",
      "[1550]\tvalid_0's binary_logloss: 0.161546\n",
      "[1550]\tvalid_0's binary_logloss: 0.16151\n",
      "[1600]\tvalid_0's binary_logloss: 0.161529\n",
      "[1600]\tvalid_0's binary_logloss: 0.161488\n",
      "[1650]\tvalid_0's binary_logloss: 0.161519\n",
      "[1650]\tvalid_0's binary_logloss: 0.16148\n",
      "[1700]\tvalid_0's binary_logloss: 0.161507\n",
      "[1700]\tvalid_0's binary_logloss: 0.161469\n",
      "[1750]\tvalid_0's binary_logloss: 0.161503\n",
      "[1750]\tvalid_0's binary_logloss: 0.161466\n",
      "[1800]\tvalid_0's binary_logloss: 0.161493\n",
      "[1800]\tvalid_0's binary_logloss: 0.161472\n",
      "[1850]\tvalid_0's binary_logloss: 0.16148\n",
      "[1850]\tvalid_0's binary_logloss: 0.161455\n",
      "[1900]\tvalid_0's binary_logloss: 0.161468\n",
      "[1900]\tvalid_0's binary_logloss: 0.161443\n",
      "[1950]\tvalid_0's binary_logloss: 0.161469\n",
      "[1950]\tvalid_0's binary_logloss: 0.16145\n",
      "[2000]\tvalid_0's binary_logloss: 0.161472\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1909]\tvalid_0's binary_logloss: 0.161461\n",
      "[2000]\tvalid_0's binary_logloss: 0.161443\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1996]\tvalid_0's binary_logloss: 0.161438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   6 out of   6 | elapsed: 13.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   6 out of   6 | elapsed: 13.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\n",
      "Best parameters set found on development set:\n",
      "{'colsample_bytree': 0.8, 'gpu_use_dp': True, 'learning_rate': 0.05, 'max_bin': 63, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.1, 'n_estimators': 2000, 'num_leaves': 18, 'reg_lambda': 10, 'subsample': 0.7, 'subsample_freq': 1}\n",
      "=====\n",
      "Best parameters set found on development set:\n",
      "-0.16136358768696385\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "#     data = all_data[((all_data.day == 7) | (all_data.day == 6)) & (all_data.is_trade != -1)]\n",
    "#     data = data.reset_index()\n",
    "\n",
    "    data = all_data[(all_data.day == 7) & (all_data.is_trade != -1)]\n",
    "    data = data.reset_index()\n",
    "    \n",
    "    del all_data\n",
    "    gc.collect()\n",
    "    \n",
    "    eval_data = data[(data.day == 7) & (data.hour >= 11)]\n",
    "    eval_set = [(eval_data[features], eval_data[target])]\n",
    "\n",
    "    lgb_clf = lgb.LGBMClassifier(objective='binary', device='gpu',  n_jobs=4, silent=False)\n",
    "\n",
    "#  参数的组合\n",
    "    lgb_param_grad = {'n_estimators': (2000, ),\n",
    "                      'learning_rate': (0.03, ),\n",
    "\n",
    "                      'max_depth': (5, ),\n",
    "                      'num_leaves': (20, ),\n",
    "                      'min_child_samples': (100, 50, 20),\n",
    "                      'min_child_weight': (0.001, ),\n",
    "                      'min_split_gain': (0.0, ),\n",
    "                      \n",
    "                      'colsample_bytree': (0.9,),\n",
    "                      'subsample': (0.7, 0.8, 0.6),\n",
    "                      'subsample_freq': (1,),\n",
    "                      \n",
    "                      'reg_lambda': (10, ),\n",
    "                      \n",
    "                      'max_bin': (63, ),\n",
    "                      \n",
    "                      'gpu_use_dp': (True, ),\n",
    "                      }\n",
    "\n",
    "    clf = GridSearchCV(lgb_clf, param_grid=lgb_param_grad, scoring='neg_log_loss',\n",
    "                       cv=CustomCV(data), n_jobs=4, verbose=1, refit=False, return_train_score=True)\n",
    "\n",
    "    clf.fit(data[features], data[target],\n",
    "            feature_name=features,\n",
    "            categorical_feature=categorical_feature,\n",
    "            early_stopping_rounds=300, eval_set=eval_set, verbose=50\n",
    "           )\n",
    "\n",
    "    print('=====')\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    print('=====')\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_score_)\n",
    "    \n",
    "    dump_pickle(clf.cv_results_, '0511_grid_search_depth_5_leaves_20.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_min_child_samples</th>\n",
       "      <th>param_num_leaves</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_min_split_gain</th>\n",
       "      <th>param_subsample_freq</th>\n",
       "      <th>param_max_bin</th>\n",
       "      <th>param_gpu_use_dp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>-0.160736</td>\n",
       "      <td>-0.157921</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>-0.160801</td>\n",
       "      <td>-0.159299</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.160698</td>\n",
       "      <td>-0.159320</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.160703</td>\n",
       "      <td>-0.158634</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.160687</td>\n",
       "      <td>-0.160235</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.160677</td>\n",
       "      <td>-0.158563</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.160717</td>\n",
       "      <td>-0.157560</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19</td>\n",
       "      <td>-0.160732</td>\n",
       "      <td>-0.158674</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.160720</td>\n",
       "      <td>-0.159634</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.160711</td>\n",
       "      <td>-0.158485</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27</td>\n",
       "      <td>-0.160763</td>\n",
       "      <td>-0.159954</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.160745</td>\n",
       "      <td>-0.159463</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.160684</td>\n",
       "      <td>-0.159904</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26</td>\n",
       "      <td>-0.160759</td>\n",
       "      <td>-0.159470</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.160721</td>\n",
       "      <td>-0.160263</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.160732</td>\n",
       "      <td>-0.159016</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25</td>\n",
       "      <td>-0.160758</td>\n",
       "      <td>-0.159220</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24</td>\n",
       "      <td>-0.160748</td>\n",
       "      <td>-0.159131</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16</td>\n",
       "      <td>-0.160723</td>\n",
       "      <td>-0.159765</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32</td>\n",
       "      <td>-0.160820</td>\n",
       "      <td>-0.159158</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.160685</td>\n",
       "      <td>-0.159938</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.160724</td>\n",
       "      <td>-0.159161</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.160650</td>\n",
       "      <td>-0.157996</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.160718</td>\n",
       "      <td>-0.160020</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.160663</td>\n",
       "      <td>-0.159983</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.160766</td>\n",
       "      <td>-0.158609</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.160664</td>\n",
       "      <td>-0.158562</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>-0.160778</td>\n",
       "      <td>-0.159172</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>22</td>\n",
       "      <td>-0.160740</td>\n",
       "      <td>-0.159981</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.160733</td>\n",
       "      <td>-0.158635</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.160658</td>\n",
       "      <td>-0.158531</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>-0.160779</td>\n",
       "      <td>-0.158612</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_test_score  mean_train_score param_reg_lambda  \\\n",
       "0                21        -0.160736         -0.157921               10   \n",
       "1                31        -0.160801         -0.159299               10   \n",
       "2                 9        -0.160698         -0.159320               10   \n",
       "3                10        -0.160703         -0.158634               10   \n",
       "4                 8        -0.160687         -0.160235               10   \n",
       "5                 5        -0.160677         -0.158563               10   \n",
       "6                12        -0.160717         -0.157560               10   \n",
       "7                19        -0.160732         -0.158674               10   \n",
       "8                14        -0.160720         -0.159634               10   \n",
       "9                11        -0.160711         -0.158485               10   \n",
       "10               27        -0.160763         -0.159954               10   \n",
       "11               23        -0.160745         -0.159463               10   \n",
       "12                6        -0.160684         -0.159904               10   \n",
       "13               26        -0.160759         -0.159470               10   \n",
       "14               15        -0.160721         -0.160263               10   \n",
       "15               18        -0.160732         -0.159016               10   \n",
       "16               25        -0.160758         -0.159220               10   \n",
       "17               24        -0.160748         -0.159131               10   \n",
       "18               16        -0.160723         -0.159765               10   \n",
       "19               32        -0.160820         -0.159158               10   \n",
       "20                7        -0.160685         -0.159938               10   \n",
       "21               17        -0.160724         -0.159161               10   \n",
       "22                1        -0.160650         -0.157996               10   \n",
       "23               13        -0.160718         -0.160020               10   \n",
       "24                3        -0.160663         -0.159983               10   \n",
       "25               28        -0.160766         -0.158609               10   \n",
       "26                4        -0.160664         -0.158562               10   \n",
       "27               29        -0.160778         -0.159172               10   \n",
       "28               22        -0.160740         -0.159981               10   \n",
       "29               20        -0.160733         -0.158635               10   \n",
       "30                2        -0.160658         -0.158531               10   \n",
       "31               30        -0.160779         -0.158612               10   \n",
       "\n",
       "   param_min_child_weight param_min_child_samples param_num_leaves  \\\n",
       "0                   0.001                     200               20   \n",
       "1                   0.001                     200               20   \n",
       "2                   0.001                     200               20   \n",
       "3                   0.001                     200               20   \n",
       "4                   0.001                     100               20   \n",
       "5                   0.001                     100               20   \n",
       "6                   0.001                     100               20   \n",
       "7                   0.001                     100               20   \n",
       "8                   0.001                      50               20   \n",
       "9                   0.001                      50               20   \n",
       "10                  0.001                      50               20   \n",
       "11                  0.001                      50               20   \n",
       "12                  0.001                      20               20   \n",
       "13                  0.001                      20               20   \n",
       "14                  0.001                      20               20   \n",
       "15                  0.001                      20               20   \n",
       "16                  0.001                     200               20   \n",
       "17                  0.001                     200               20   \n",
       "18                  0.001                     200               20   \n",
       "19                  0.001                     200               20   \n",
       "20                  0.001                     100               20   \n",
       "21                  0.001                     100               20   \n",
       "22                  0.001                     100               20   \n",
       "23                  0.001                     100               20   \n",
       "24                  0.001                      50               20   \n",
       "25                  0.001                      50               20   \n",
       "26                  0.001                      50               20   \n",
       "27                  0.001                      50               20   \n",
       "28                  0.001                      20               20   \n",
       "29                  0.001                      20               20   \n",
       "30                  0.001                      20               20   \n",
       "31                  0.001                      20               20   \n",
       "\n",
       "   param_subsample param_colsample_bytree param_min_split_gain  \\\n",
       "0              0.7                    0.9                    0   \n",
       "1              0.8                    0.9                    0   \n",
       "2              0.7                    0.9                  0.1   \n",
       "3              0.8                    0.9                  0.1   \n",
       "4              0.7                    0.9                    0   \n",
       "5              0.8                    0.9                    0   \n",
       "6              0.7                    0.9                  0.1   \n",
       "7              0.8                    0.9                  0.1   \n",
       "8              0.7                    0.9                    0   \n",
       "9              0.8                    0.9                    0   \n",
       "10             0.7                    0.9                  0.1   \n",
       "11             0.8                    0.9                  0.1   \n",
       "12             0.7                    0.9                    0   \n",
       "13             0.8                    0.9                    0   \n",
       "14             0.7                    0.9                  0.1   \n",
       "15             0.8                    0.9                  0.1   \n",
       "16             0.7                    0.8                    0   \n",
       "17             0.8                    0.8                    0   \n",
       "18             0.7                    0.8                  0.1   \n",
       "19             0.8                    0.8                  0.1   \n",
       "20             0.7                    0.8                    0   \n",
       "21             0.8                    0.8                    0   \n",
       "22             0.7                    0.8                  0.1   \n",
       "23             0.8                    0.8                  0.1   \n",
       "24             0.7                    0.8                    0   \n",
       "25             0.8                    0.8                    0   \n",
       "26             0.7                    0.8                  0.1   \n",
       "27             0.8                    0.8                  0.1   \n",
       "28             0.7                    0.8                    0   \n",
       "29             0.8                    0.8                    0   \n",
       "30             0.7                    0.8                  0.1   \n",
       "31             0.8                    0.8                  0.1   \n",
       "\n",
       "   param_subsample_freq param_max_bin param_gpu_use_dp  \n",
       "0                     1            63             True  \n",
       "1                     1            63             True  \n",
       "2                     1            63             True  \n",
       "3                     1            63             True  \n",
       "4                     1            63             True  \n",
       "5                     1            63             True  \n",
       "6                     1            63             True  \n",
       "7                     1            63             True  \n",
       "8                     1            63             True  \n",
       "9                     1            63             True  \n",
       "10                    1            63             True  \n",
       "11                    1            63             True  \n",
       "12                    1            63             True  \n",
       "13                    1            63             True  \n",
       "14                    1            63             True  \n",
       "15                    1            63             True  \n",
       "16                    1            63             True  \n",
       "17                    1            63             True  \n",
       "18                    1            63             True  \n",
       "19                    1            63             True  \n",
       "20                    1            63             True  \n",
       "21                    1            63             True  \n",
       "22                    1            63             True  \n",
       "23                    1            63             True  \n",
       "24                    1            63             True  \n",
       "25                    1            63             True  \n",
       "26                    1            63             True  \n",
       "27                    1            63             True  \n",
       "28                    1            63             True  \n",
       "29                    1            63             True  \n",
       "30                    1            63             True  \n",
       "31                    1            63             True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gird = load_pickle('0511_grid_search_leaves_20_nan_yym.pkl')\n",
    "\n",
    "pd.DataFrame(data=gird)[['rank_test_score', 'mean_test_score', 'mean_train_score', 'param_reg_lambda', 'param_min_child_weight',\n",
    "                                    'param_min_child_samples', 'param_num_leaves', 'param_subsample', 'param_colsample_bytree', \n",
    "                                    'param_min_split_gain','param_subsample_freq',\n",
    "                                    'param_max_bin', 'param_gpu_use_dp']]\n",
    "\n",
    "# pd.DataFrame(data=clf.cv_results_)[['rank_test_score', 'mean_test_score', 'mean_train_score', 'param_reg_lambda', 'param_num_leaves', 'param_colsample_bytree', \n",
    "# #                                     'param_min_split_gain','param_subsample_freq',\n",
    "#                                     'param_max_bin', 'param_gpu_use_dp']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
