{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import time\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import load_pickle, dump_pickle, get_feature_value, feature_spearmanr, feature_target_spearmanr, addCrossFeature, calibration\n",
    "from utils import raw_data_path, feature_data_path, cache_pkl_path, analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_path = feature_data_path + 'all_data_all_features_new_0512.pkl'\n",
    "all_data = load_pickle(all_data_path)\n",
    "\n",
    "target = 'is_trade'\n",
    "\n",
    "features = load_pickle('all_features_day_4567.pkl')\n",
    "categorical_feature = load_pickle('categorical_feature.pkl')\n",
    "\n",
    "len(features), len(categorical_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5369478, 573)\n",
      "(1209768, 573)\n"
     ]
    }
   ],
   "source": [
    "train_data = all_data[(all_data.is_trade >= 0)]\n",
    "test_data = all_data[all_data.is_trade == -2]\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's binary_logloss: 0.233822\n",
      "[40]\ttraining's binary_logloss: 0.117862\n",
      "[100]\ttraining's binary_logloss: 0.0694651\n",
      "[120]\ttraining's binary_logloss: 0.0683176\n",
      "[140]\ttraining's binary_logloss: 0.0677381\n",
      "[160]\ttraining's binary_logloss: 0.0673753\n",
      "[180]\ttraining's binary_logloss: 0.067126\n",
      "[200]\ttraining's binary_logloss: 0.0669357\n",
      "[220]\ttraining's binary_logloss: 0.066784\n",
      "[240]\ttraining's binary_logloss: 0.0666637\n",
      "[260]\ttraining's binary_logloss: 0.0665491\n",
      "[280]\ttraining's binary_logloss: 0.0664565\n",
      "[300]\ttraining's binary_logloss: 0.066372\n",
      "[320]\ttraining's binary_logloss: 0.0662915\n",
      "[340]\ttraining's binary_logloss: 0.0662156\n",
      "[360]\ttraining's binary_logloss: 0.0661457\n",
      "[380]\ttraining's binary_logloss: 0.0660867\n",
      "[400]\ttraining's binary_logloss: 0.06603\n",
      "[420]\ttraining's binary_logloss: 0.0659752\n",
      "[440]\ttraining's binary_logloss: 0.0659229\n",
      "[460]\ttraining's binary_logloss: 0.0658731\n",
      "[480]\ttraining's binary_logloss: 0.0658247\n",
      "[500]\ttraining's binary_logloss: 0.0657756\n",
      "[520]\ttraining's binary_logloss: 0.0657307\n",
      "[540]\ttraining's binary_logloss: 0.065686\n",
      "[560]\ttraining's binary_logloss: 0.0656425\n",
      "[580]\ttraining's binary_logloss: 0.0656036\n",
      "[600]\ttraining's binary_logloss: 0.0655602\n",
      "[620]\ttraining's binary_logloss: 0.0655191\n",
      "[640]\ttraining's binary_logloss: 0.0654752\n",
      "[660]\ttraining's binary_logloss: 0.0654378\n",
      "[680]\ttraining's binary_logloss: 0.0653999\n",
      "[700]\ttraining's binary_logloss: 0.0653598\n",
      "[720]\ttraining's binary_logloss: 0.0653224\n",
      "[740]\ttraining's binary_logloss: 0.0652877\n",
      "[760]\ttraining's binary_logloss: 0.0652509\n",
      "[780]\ttraining's binary_logloss: 0.0652178\n",
      "[800]\ttraining's binary_logloss: 0.0651829\n",
      "[820]\ttraining's binary_logloss: 0.0651471\n",
      "[840]\ttraining's binary_logloss: 0.0651129\n",
      "[860]\ttraining's binary_logloss: 0.0650791\n",
      "[880]\ttraining's binary_logloss: 0.065045\n",
      "[900]\ttraining's binary_logloss: 0.0650124\n",
      "[920]\ttraining's binary_logloss: 0.0649789\n",
      "[940]\ttraining's binary_logloss: 0.0649443\n",
      "[960]\ttraining's binary_logloss: 0.064914\n",
      "[980]\ttraining's binary_logloss: 0.0648828\n",
      "[1000]\ttraining's binary_logloss: 0.064853\n",
      "[1020]\ttraining's binary_logloss: 0.064821\n",
      "[1040]\ttraining's binary_logloss: 0.0647904\n",
      "[1060]\ttraining's binary_logloss: 0.0647583\n",
      "[1080]\ttraining's binary_logloss: 0.0647288\n",
      "[1100]\ttraining's binary_logloss: 0.0646986\n",
      "[1120]\ttraining's binary_logloss: 0.0646696\n",
      "[1140]\ttraining's binary_logloss: 0.0646386\n",
      "[1160]\ttraining's binary_logloss: 0.0646088\n",
      "[1180]\ttraining's binary_logloss: 0.0645776\n",
      "[1200]\ttraining's binary_logloss: 0.0645469\n",
      "[1220]\ttraining's binary_logloss: 0.0645175\n",
      "[1240]\ttraining's binary_logloss: 0.0644875\n",
      "[1260]\ttraining's binary_logloss: 0.0644584\n",
      "[1280]\ttraining's binary_logloss: 0.0644294\n",
      "[1300]\ttraining's binary_logloss: 0.0644022\n",
      "[1320]\ttraining's binary_logloss: 0.0643733\n",
      "[1340]\ttraining's binary_logloss: 0.0643448\n",
      "[1360]\ttraining's binary_logloss: 0.0643156\n",
      "[1380]\ttraining's binary_logloss: 0.0642895\n",
      "[1400]\ttraining's binary_logloss: 0.0642589\n",
      "[1420]\ttraining's binary_logloss: 0.0642304\n",
      "[1440]\ttraining's binary_logloss: 0.0642011\n",
      "[1460]\ttraining's binary_logloss: 0.0641734\n",
      "[1480]\ttraining's binary_logloss: 0.0641455\n",
      "[1500]\ttraining's binary_logloss: 0.0641165\n",
      "[1520]\ttraining's binary_logloss: 0.0640895\n",
      "[1540]\ttraining's binary_logloss: 0.064063\n",
      "[1560]\ttraining's binary_logloss: 0.0640364\n",
      "[1580]\ttraining's binary_logloss: 0.0640088\n",
      "[1600]\ttraining's binary_logloss: 0.0639799\n",
      "[1620]\ttraining's binary_logloss: 0.0639535\n",
      "[1640]\ttraining's binary_logloss: 0.063925\n",
      "[1660]\ttraining's binary_logloss: 0.0638985\n",
      "[1680]\ttraining's binary_logloss: 0.0638721\n",
      "[1700]\ttraining's binary_logloss: 0.0638463\n",
      "[1720]\ttraining's binary_logloss: 0.0638192\n",
      "[1740]\ttraining's binary_logloss: 0.0637922\n",
      "[1760]\ttraining's binary_logloss: 0.0637662\n",
      "[1780]\ttraining's binary_logloss: 0.0637402\n",
      "[1800]\ttraining's binary_logloss: 0.0637136\n",
      "[1820]\ttraining's binary_logloss: 0.0636887\n",
      "[1840]\ttraining's binary_logloss: 0.063661\n",
      "[1860]\ttraining's binary_logloss: 0.0636328\n",
      "[1880]\ttraining's binary_logloss: 0.0636072\n",
      "[1900]\ttraining's binary_logloss: 0.0635816\n",
      "[1920]\ttraining's binary_logloss: 0.0635562\n",
      "[1940]\ttraining's binary_logloss: 0.0635302\n",
      "[1960]\ttraining's binary_logloss: 0.0635035\n",
      "[1980]\ttraining's binary_logloss: 0.0634772\n",
      "[2000]\ttraining's binary_logloss: 0.0634512\n",
      "[2020]\ttraining's binary_logloss: 0.0634262\n",
      "[2040]\ttraining's binary_logloss: 0.0633998\n",
      "[2060]\ttraining's binary_logloss: 0.0633746\n",
      "[2080]\ttraining's binary_logloss: 0.0633507\n",
      "[2100]\ttraining's binary_logloss: 0.0633234\n",
      "[2120]\ttraining's binary_logloss: 0.0632974\n",
      "[2140]\ttraining's binary_logloss: 0.0632711\n",
      "[2160]\ttraining's binary_logloss: 0.0632447\n",
      "[2180]\ttraining's binary_logloss: 0.0632205\n",
      "[2200]\ttraining's binary_logloss: 0.0631961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qwc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_train_data = lgb.Dataset(\n",
    "    train_data[features], label=train_data[target], feature_name=features, categorical_feature=categorical_feature)\n",
    "\n",
    "\n",
    "param = {'application': 'binary',\n",
    "         'metric': 'binary_logloss',\n",
    "\n",
    "         'learning_rate': 0.05,\n",
    "\n",
    "         'max_depth': 5,\n",
    "         'num_leaves': 20,\n",
    "\n",
    "         'min_data_in_leaf': 200,\n",
    "         'min_sum_hessian_in_leaf': 0.001,\n",
    "         'min_gain_to_split': 0.1,\n",
    "\n",
    "         'feature_fraction': 0.8,\n",
    "         'bagging_fraction': 0.7,\n",
    "         'bagging_freq': 1,\n",
    "\n",
    "         'lambda_l2': 10,\n",
    "         'max_bin': 63,\n",
    "\n",
    "         'device': 'gpu',\n",
    "         'gpu_use_dp': True,\n",
    "         \n",
    "#          'num_threads': 1,\n",
    "         }\n",
    "\n",
    "\n",
    "valid_sets = [lgb_train_data,]\n",
    "\n",
    "bst = lgb.train(param, lgb_train_data, \n",
    "                num_boost_round=2200, \n",
    "                categorical_feature=categorical_feature,\n",
    "                valid_sets=valid_sets, verbose_eval=20,)\n",
    "\n",
    "\n",
    "test_data['predicted_score'] = bst.predict(test_data[features])\n",
    "\n",
    "test_data[['instance_id', 'predicted_score']].to_csv(\n",
    "    '20180514-2200-day-4567.txt', index=False, sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034462307352375605"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict_train = bst.predict(train_data[features])\n",
    "predict_test = bst.predict(test_data[features])\n",
    "\n",
    "# train_ctr = float(sum(predict_train)/float(len(predict_train)))\n",
    "test_ctr = float(sum(predict_test)/float(len(predict_test)))\n",
    "\n",
    "# train_ctr, \n",
    "test_ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qwc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0.041335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.039952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>0.036357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.036461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0.036538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>0.037059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>0.037062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19</td>\n",
       "      <td>0.036812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>0.034777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>0.030587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22</td>\n",
       "      <td>0.027387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23</td>\n",
       "      <td>0.026803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hour  predicted_score\n",
       "0     12         0.041335\n",
       "1     13         0.039952\n",
       "2     14         0.036357\n",
       "3     15         0.036461\n",
       "4     16         0.036538\n",
       "5     17         0.037059\n",
       "6     18         0.037062\n",
       "7     19         0.036812\n",
       "8     20         0.034777\n",
       "9     21         0.030587\n",
       "10    22         0.027387\n",
       "11    23         0.026803"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['predicted_score'] = bst.predict(test_data[features])\n",
    "ctr = test_data.groupby(['hour'])['predicted_score'].mean().reset_index().rename(columns={0: 'ctr'})\n",
    "ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03949020931050776"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "p1 = pd.read_csv('20180513-2900-day-47.txt', sep=' ')\n",
    "p2 = pd.read_csv('201805012_7all_2050.txt', sep=' ')\n",
    "\n",
    "p2['predicted_score'] = p2['predicted_score'] * 0.5 + p1['predicted_score'] * 0.5\n",
    "\n",
    "\n",
    "p2[['instance_id', 'predicted_score']].to_csv(\n",
    "    '20180513-combination.txt', index=False, sep=' ')\n",
    "\n",
    "test_ctr = float(sum(p2['predicted_score'])/float(len(p2['predicted_score'])))\n",
    "\n",
    "test_ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查提交数据 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 最终版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "201805012_7all_2050.txt\n",
    "20180513-2900-day-47.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
